diff --git a/AUTHORS b/AUTHORS
index 93ce012..d73ea7d 100644
--- a/AUTHORS
+++ b/AUTHORS
@@ -18,6 +18,7 @@ Ask Solem <ask@celeryproject.org>
 Basil Mironenko <bmironenko@ddn.com>
 Bobby Beever <bobby.beever@yahoo.com>
 Brian Bernstein
+Brian Bouterse <bmbouter@redhat.com>
 C Anthony Risinger <anthony+corvisa.com@xtfx.me>
 Christophe Chauvet <christophe.chauvet@gmail.com>
 Christopher Grebs <cg@webshox.org>
diff --git a/README.rst b/README.rst
index f985576..4b59cc4 100644
--- a/README.rst
+++ b/README.rst
@@ -22,7 +22,7 @@ Features
 * Allows application authors to support several message server
   solutions by using pluggable transports.
 
-    * AMQP transport using the `py-amqp`_ or `librabbitmq`_ client libraries.
+    * AMQP transport using the `py-amqp`_, `librabbitmq`_, or `qpid-python`_ libraries.
 
     * High performance AMQP transport written in C - when using `librabbitmq`_
 
@@ -60,6 +60,7 @@ and the `Wikipedia article about AMQP`_.
 .. _`RabbitMQ`: http://www.rabbitmq.com/
 .. _`AMQP`: http://amqp.org
 .. _`py-amqp`: http://pypi.python.org/pypi/amqp/
+.. _`qpid-python`: http://pypi.python.org/pypi/qpid-python/
 .. _`Redis`: http://code.google.com/p/redis/
 .. _`Amazon SQS`: http://aws.amazon.com/sqs/
 .. _`MongoDB`: http://www.mongodb.org/
@@ -86,6 +87,8 @@ Transport Comparison
 +---------------+----------+------------+------------+---------------+
 | *amqp*        | Native   | Yes        | Yes        | Yes           |
 +---------------+----------+------------+------------+---------------+
+| *qpid*        | Native   | Yes        | Yes        | Yes           |
++---------------+----------+------------+------------+---------------+
 | *redis*       | Virtual  | Yes        | Yes        | Yes (PUB/SUB) |
 +---------------+----------+------------+------------+---------------+
 | *mongodb*     | Virtual  | Yes        | Yes        | Yes           |
diff --git a/docs/reference/index.rst b/docs/reference/index.rst
index 6898a96..db2e9b6 100644
--- a/docs/reference/index.rst
+++ b/docs/reference/index.rst
@@ -31,6 +31,7 @@
     kombu.transport
     kombu.transport.pyamqp
     kombu.transport.librabbitmq
+    kombu.transport.qpid
     kombu.transport.memory
     kombu.transport.redis
     kombu.transport.zmq
diff --git a/docs/reference/kombu.transport.qpid.rst b/docs/reference/kombu.transport.qpid.rst
new file mode 100644
index 0000000..4e152c8
--- /dev/null
+++ b/docs/reference/kombu.transport.qpid.rst
@@ -0,0 +1,35 @@
+.. currentmodule:: kombu.transport.qpid
+
+.. automodule:: kombu.transport.qpid
+
+    .. contents::
+        :local:
+
+    Transport
+    ---------
+
+    .. autoclass:: Transport
+        :members:
+        :undoc-members:
+
+    Connection
+    ----------
+
+    .. autoclass:: Connection
+        :members:
+        :undoc-members:
+
+    Channel
+    -------
+
+    .. autoclass:: Channel
+        :members:
+        :undoc-members:
+
+    Message
+    -------
+
+    .. autoclass:: Message
+        :members:
+        :undoc-members:
+
diff --git a/docs/userguide/connections.rst b/docs/userguide/connections.rst
index f97b4b7..234d16e 100644
--- a/docs/userguide/connections.rst
+++ b/docs/userguide/connections.rst
@@ -10,7 +10,7 @@ Basics
 ======
 
 To send and receive messages you need a transport and a connection.
-There are several transports to choose from (amqp, librabbitmq, redis, in-memory, etc.),
+There are several transports to choose from (amqp, librabbitmq, redis, qpid, in-memory, etc.),
 and you can even create your own. The default transport is amqp.
 
 Create a connection using the default transport::
@@ -73,6 +73,9 @@ All of these are valid URLs::
     # Using Redis over a Unix socket
     redis+socket:///tmp/redis.sock
 
+    # Using Qpid
+    qpid://localhost/
+
     # Using virtual host '/foo'
     amqp://localhost//foo
 
@@ -114,10 +117,10 @@ keyword arguments, these are:
 :transport: Default transport if not provided in the URL.
   Can be a string specifying the path to the class. (e.g.
   ``kombu.transport.pyamqp:Transport``), or one of the aliases:
-  ``pyamqp``, ``librabbitmq``, ``redis``, ``memory``, and so on.
+  ``pyamqp``, ``librabbitmq``, ``redis``, ``qpid``, ``memory``, and so on.
 
 :ssl: Use SSL to connect to the server. Default is ``False``.
-  Only supported by the amqp transport.
+  Only supported by the amqp and qpid transports.
 :insist: Insist on connecting to a server.
   *No longer supported, relic from AMQP 0.8*
 :connect_timeout: Timeout in seconds for connecting to the
@@ -129,7 +132,7 @@ keyword arguments, these are:
 AMQP Transports
 ===============
 
-There are 3 transports available for AMQP use.
+There are 4 transports available for AMQP use.
 
 1. ``pyamqp`` uses the pure Python library ``amqp``, automatically
    installed with Kombu.
@@ -137,6 +140,9 @@ There are 3 transports available for AMQP use.
    This requires the ``librabbitmq`` Python package to be installed, which
    automatically compiles the C library.
 3. ``amqp`` tries to use ``librabbitmq`` but falls back to ``pyamqp``.
+4. ``qpid`` uses the pure Python library ``qpid.messaging``, automatically
+   installed with Kombu.  The Qpid library uses AMQP, but uses custom
+   extensions specifically supported by the Apache Qpid Broker.
 
 For the highest performance, you should install the ``librabbitmq`` package.
 To ensure librabbitmq is used, you can explicitly specify it in the
@@ -150,6 +156,8 @@ Transport Comparison
 +---------------+----------+------------+------------+---------------+
 | *amqp*        | Native   | Yes        | Yes        | Yes           |
 +---------------+----------+------------+------------+---------------+
+| *qpid*        | Native   | Yes        | Yes        | Yes           |
++---------------+----------+------------+------------+---------------+
 | *redis*       | Virtual  | Yes        | Yes        | Yes (PUB/SUB) |
 +---------------+----------+------------+------------+---------------+
 | *mongodb*     | Virtual  | Yes        | Yes        | Yes           |
diff --git a/funtests/tests/test_qpid.py b/funtests/tests/test_qpid.py
new file mode 100644
index 0000000..f4e8a8e
--- /dev/null
+++ b/funtests/tests/test_qpid.py
@@ -0,0 +1,13 @@
+from nose import SkipTest
+
+from funtests import transport
+
+class test_qpid(transport.TransportCase):
+    transport = 'qpid'
+    prefix = 'qpid'
+
+    def before_connect(self):
+        try:
+            import qpid.messaging  # noqa
+        except ImportError:
+            raise SkipTest('qpid.messaging not installed')
\ No newline at end of file
diff --git a/kombu/connection.py b/kombu/connection.py
index 85b8f5e..acd1713 100644
--- a/kombu/connection.py
+++ b/kombu/connection.py
@@ -70,8 +70,8 @@ class Connection(object):
 
     .. admonition:: SSL compatibility
 
-        SSL currently only works with the py-amqp & amqplib transports.
-        For other transports you can use stunnel.
+        SSL currently only works with the py-amqp, amqplib, and qpid
+        transports.  For other transports you can use stunnel.
 
     :keyword hostname: Default host name/address if not provided in the URL.
     :keyword userid: Default user name if not provided in the URL.
diff --git a/kombu/tests/transport/test_qpid.py b/kombu/tests/transport/test_qpid.py
new file mode 100644
index 0000000..d0f3fa2
--- /dev/null
+++ b/kombu/tests/transport/test_qpid.py
@@ -0,0 +1,1357 @@
+from __future__ import absolute_import
+
+import Queue
+import socket
+import time
+
+from itertools import count
+
+QPID_NOT_AVAILABLE = False
+try:
+    import qpid.messaging.exceptions
+    import qpidtoollibs     # noqa
+except ImportError:
+    QPID_NOT_AVAILABLE = True
+
+import kombu.five
+from kombu.transport.qpid import QpidMessagingExceptionHandler, QoS, Message
+from kombu.transport.qpid import Channel, FDShimThread, FDShim
+from kombu.transport.qpid import Connection, Transport
+from kombu.transport.virtual import Base64
+from kombu.utils.compat import OrderedDict
+from kombu.tests.case import Case, Mock, SkipTest
+from kombu.tests.case import patch, skip_if_not_module
+
+
+class ExtraAssertionsMixin(object):
+    """A mixin class adding assertDictEqual and assertDictContainsSubset"""
+
+    def assertDictEqual(self, a, b):
+        """
+        Test that two dictionaries are equal.
+
+        Implemented here because this method was not available until Python
+        2.6.  This asserts that the unique set of keys are the same in a and b.
+        Also asserts that the value of each key is the same in a and b using
+        the is operator.
+        """
+        self.assertEqual(set(a.keys()), set(b.keys()))
+        for key in a.keys():
+            self.assertEqual(a[key], b[key])
+
+    def assertDictContainsSubset(self, a, b):
+        """
+        Assert that all the key/value pairs in a exist in b.
+        """
+        for key in a.keys():
+            self.assertTrue(key in b)
+            self.assertTrue(a[key] == b[key])
+
+
+class TestQpidMessagingExceptionHandler(Case):
+
+    allowed_string = 'object in use'
+    not_allowed_string = 'a different string'
+
+    def setUp(self):
+        """Create a mock ExceptionHandler for testing by this object."""
+        if QPID_NOT_AVAILABLE:
+            raise SkipTest('qpid.messaging not installed')
+        self.handler = QpidMessagingExceptionHandler(self.allowed_string)
+
+    def test_string_stored(self):
+        """Assert that the allowed_exception_string is stored correctly"""
+        handler_string = self.handler.allowed_exception_string
+        self.assertEqual(self.allowed_string, handler_string)
+
+    def test_exception_positive(self):
+        """Assert that an exception is silenced if it contains the
+        allowed_string text
+        """
+        exception_to_raise = Exception(self.allowed_string)
+
+        def exception_raise_func():
+            raise exception_to_raise
+        decorated_func = self.handler(exception_raise_func)
+        try:
+            decorated_func()
+        except:
+            self.fail("QpidMessagingExceptionHandler allowed an exception "
+                      "to be raised that should have been silenced!")
+
+    def test_exception_negative(self):
+        """Assert that an exception that does not contain the
+        allowed_string text is properly raised
+        """
+        exception_to_raise = Exception(self.not_allowed_string)
+
+        def exception_raise_func():
+            raise exception_to_raise
+        decorated_func = self.handler(exception_raise_func)
+        self.assertRaises(Exception, decorated_func)
+
+
+class TestQoS(Case):
+
+    def mock_message_factory(self):
+        """Create and return a mock message tag and delivery_tag."""
+        m_delivery_tag = self.delivery_tag_generator.next()
+        m = 'message %s' % m_delivery_tag
+        return (m, m_delivery_tag)
+
+    def add_n_messages_to_qos(self, n, qos):
+        """Add N mock messages into the passed in qos object"""
+        for i in range(n):
+            self.add_message_to_qos(qos)
+
+    def add_message_to_qos(self, qos):
+        """Add a single mock message into the passed in qos object.
+
+        Uses the mock_message_factory() to create the message and
+        delivery_tag.
+        """
+        m, m_delivery_tag = self.mock_message_factory()
+        qos.append(m, m_delivery_tag)
+
+    def setUp(self):
+        """Create two QoS objects for use by this test class.
+
+        One with no prefetch_limit, and the other with a prefetch limit of
+        2.
+        """
+        if QPID_NOT_AVAILABLE:
+            raise SkipTest('qpid.messaging not installed')
+        self.qos_no_limit = QoS()
+        self.qos_limit_2 = QoS(prefetch_count=2)
+        self.delivery_tag_generator = count(1)
+
+    def test_init_no_params(self):
+        """Check that internal state is correct after initialization"""
+        self.assertEqual(self.qos_no_limit.prefetch_count, 0)
+        self.assertTrue(isinstance(self.qos_no_limit._not_yet_acked,
+                                   OrderedDict))
+
+    def test_init_with_params(self):
+        """Check that internal state is correct after initialization with
+        prefetch_count.
+        """
+        self.assertEqual(self.qos_limit_2.prefetch_count, 2)
+
+    def test_can_consume_no_limit(self):
+        """can_consume shall always return True with no prefetch limits"""
+        self.assertTrue(self.qos_no_limit.can_consume())
+        self.add_n_messages_to_qos(3, self.qos_no_limit)
+        self.assertTrue(self.qos_no_limit.can_consume())
+
+    def test_can_consume_with_limit(self):
+        """can_consume shall return False only when the QoS holds
+        prefetch_count number of messages
+        """
+        self.assertTrue(self.qos_limit_2.can_consume())
+        self.add_n_messages_to_qos(2, self.qos_limit_2)
+        self.assertFalse(self.qos_limit_2.can_consume())
+
+    def test_can_consume_max_estimate_no_limit(self):
+        """can_consume_max_estimate shall always return 1 with no prefetch
+        limits
+        """
+        self.assertEqual(self.qos_no_limit.can_consume_max_estimate(), 1)
+        self.add_n_messages_to_qos(3, self.qos_no_limit)
+        self.assertEqual(self.qos_no_limit.can_consume_max_estimate(), 1)
+
+    def test_can_consume_max_estimate_with_limit(self):
+        """while prefetch limits are enabled, can_consume_max_estimate shall
+        return (prefetch_limit - #messages) as the number of messages is
+        incremented from 0 to prefetch_limit
+        """
+        self.assertEqual(self.qos_limit_2.can_consume_max_estimate(), 2)
+        self.add_message_to_qos(self.qos_limit_2)
+        self.assertEqual(self.qos_limit_2.can_consume_max_estimate(), 1)
+        self.add_message_to_qos(self.qos_limit_2)
+        self.assertEqual(self.qos_limit_2.can_consume_max_estimate(), 0)
+
+    def test_append(self):
+        """Append two messages and check inside the QoS object that they
+        were put into the internal data structures correctly
+        """
+        qos = self.qos_no_limit
+        m1, m1_tag = self.mock_message_factory()
+        m2, m2_tag = self.mock_message_factory()
+        qos.append(m1, m1_tag)
+        length_not_yet_acked = len(qos._not_yet_acked)
+        self.assertEqual(length_not_yet_acked, 1)
+        checked_message1 = qos._not_yet_acked[m1_tag]
+        self.assertTrue(m1 is checked_message1)
+        qos.append(m2, m2_tag)
+        length_not_yet_acked = len(qos._not_yet_acked)
+        self.assertEqual(length_not_yet_acked, 2)
+        checked_message2 = qos._not_yet_acked[m2_tag]
+        self.assertTrue(m2 is checked_message2)
+
+    def test_get(self):
+        """Append two messages, and use get to receive them"""
+        qos = self.qos_no_limit
+        m1, m1_tag = self.mock_message_factory()
+        m2, m2_tag = self.mock_message_factory()
+        qos.append(m1, m1_tag)
+        qos.append(m2, m2_tag)
+        message1 = qos.get(m1_tag)
+        message2 = qos.get(m2_tag)
+        self.assertTrue(m1 is message1)
+        self.assertTrue(m2 is message2)
+
+    def test_ack(self):
+        """Load a mock message, ack the message, and ensure the right
+        call is made to the acknowledge method in the qpid.messaging client
+        library
+        """
+        message = Mock()
+        qos = self.qos_no_limit
+        qos.append(message, 1)
+        qos.ack(1)
+        message._receiver.session.acknowledge.assert_called_with(
+            message=message)
+
+    @patch('qpid.messaging.Disposition')
+    @patch('qpid.messaging.RELEASED')
+    def test_ack_requeue_true(self, mock_RELEASED, mock_QpidDisposition):
+        """Load a mock message, reject the message with requeue=True,
+        and ensure the right call to acknowledge is made.
+        """
+        message = Mock()
+        mock_QpidDisposition.return_value = 'disposition'
+        qos = self.qos_no_limit
+        qos.append(message, 1)
+        qos.reject(1, requeue=True)
+        mock_QpidDisposition.assert_called_with(mock_RELEASED)
+        message._receiver.session.acknowledge.assert_called_with(
+            message=message, disposition='disposition')
+
+    @patch('qpid.messaging.Disposition')
+    @patch('qpid.messaging.REJECTED')
+    def test_ack_requeue_false(self, mock_REJECTED, mock_QpidDisposition):
+        """Load a mock message, reject the message with requeue=False,
+        and ensure the right call to acknowledge is made.
+        """
+        message = Mock()
+        mock_QpidDisposition.return_value = 'disposition'
+        qos = self.qos_no_limit
+        qos.append(message, 1)
+        qos.reject(1, requeue=False)
+        mock_QpidDisposition.assert_called_with(mock_REJECTED)
+        message._receiver.session.acknowledge.assert_called_with(
+            message=message, disposition='disposition')
+
+
+class TestFDShimThread(Case):
+
+    def setUp(self):
+        """Create a mock FDShimThread object and associated objects."""
+        if QPID_NOT_AVAILABLE:
+            raise SkipTest('qpid.messaging not installed')
+        self.mock_get_qpid_connection = Mock()
+        self.mock_session = Mock()
+        self.mock_get_qpid_connection().session = Mock(
+            return_value=self.mock_session)
+        self.mock_receiver = Mock()
+        self.mock_session.receiver = Mock(return_value=self.mock_receiver)
+        self.mock_queue = Mock()
+        self.mock_delivery_queue = Mock()
+        self.my_thread = FDShimThread(self.mock_get_qpid_connection,
+                                      self.mock_queue,
+                                      self.mock_delivery_queue)
+
+    def test_init_variables(self):
+        """Test that all simple init params are internally stored
+        correctly
+        """
+        self.assertTrue(self.my_thread._queue is self.mock_queue)
+        self.assertTrue(self.my_thread._delivery_queue is
+                        self.mock_delivery_queue)
+        self.assertFalse(self.my_thread._is_killed)
+
+    def test_session_gets_made(self):
+        """Test that a session is created"""
+        self.mock_get_qpid_connection().session.assert_called_with()
+
+    def test_session_gets_stored(self):
+        """Test that a session is saved properly after being created"""
+        self.assertTrue(self.mock_session is self.my_thread._session)
+
+    def test_receiver_gets_made(self):
+        """Test that a receiver is created listening on the queue"""
+        self.mock_session.receiver.assert_called_with(self.mock_queue)
+
+    def test_receiver_gets_stored(self):
+        """Test that a receiver is saved properly after being created"""
+        self.assertTrue(self.mock_receiver is self.my_thread._receiver)
+
+    def test_kill(self):
+        """Ensure that a call to the thread main method run() will exit
+        properly when kill() has been called.
+        """
+        self.my_thread.kill()
+        self.my_thread.run()
+
+    def test_receiver_cleanup(self):
+        """Ensure that when a thread main method exits, that close() is
+        called on the receiver.
+        """
+        self.my_thread.kill()
+        self.my_thread.run()
+        self.mock_receiver.close.assert_called_with()
+
+    def test_session_cleanup(self):
+        """Ensure that when a thread main method exits, that close() is
+        called on the session.
+        """
+        self.my_thread.kill()
+        self.my_thread.run()
+        self.mock_session.close.assert_called_with()
+
+    def test_call_to_fetch_raise_empty(self):
+        """Ensure the call to fetch() occurs, and with the proper timeout.
+        Raises an Empty exception.
+        """
+        QpidEmpty = qpid.messaging.exceptions.Empty
+        exception_causing_exit = Exception('Exit run() method')
+        self.mock_receiver.fetch = Mock(side_effect=[QpidEmpty(),
+                                                     exception_causing_exit])
+        try:
+            self.my_thread.run()
+        except Exception as err:
+            self.assertEqual(exception_causing_exit, err)
+        self.mock_receiver.fetch.assert_called_with(
+            timeout=FDShimThread.block_timeout)
+
+    def test_call_to_fetch_return_message(self):
+        """Ensure the call to fetch() occurs, that the response bundle is
+        built correctly is called as the only argument to receiver.put()
+        """
+        mock_response = Mock()
+        mock_source = Mock()
+        exception_causing_exit = Exception('Exit run() method')
+        response_bundle = (mock_source, mock_response)
+        self.mock_receiver.fetch = Mock(return_value=mock_response)
+        self.mock_receiver.source = mock_source
+        self.mock_delivery_queue.put.side_effect = exception_causing_exit
+        try:
+            self.my_thread.run()
+        except Exception as err:
+            self.assertEqual(exception_causing_exit, err)
+        self.mock_receiver.fetch.assert_called_with(
+            timeout=FDShimThread.block_timeout)
+        self.mock_delivery_queue.put.assert_called_with(response_bundle)
+
+
+class TestFDShim(Case):
+
+    def setUp(self):
+        """Create a test shim to use """
+        if QPID_NOT_AVAILABLE:
+            raise SkipTest('qpid.messaging not installed')
+        self.mock_queue_from_fdshim = Mock()
+        self.mock_delivery_queue = Mock()
+        self.my_fdshim = FDShim(self.mock_queue_from_fdshim,
+                                self.mock_delivery_queue)
+
+    def test_init_variables(self):
+        """Test that all simple init params are internally stored
+        correctly
+        """
+        self.assertTrue(self.my_fdshim.queue_from_fdshim is
+                        self.mock_queue_from_fdshim)
+        self.assertTrue(self.my_fdshim.delivery_queue is
+                        self.mock_delivery_queue)
+        self.assertFalse(self.my_fdshim._is_killed)
+
+    def test_kill(self):
+        """Ensure that a call to the thread main method run() will exit
+        properly when kill() has been called.
+        """
+        self.my_fdshim.kill()
+        self.my_fdshim.monitor_consumers()
+
+    def test_call_to_get_raise_empty(self):
+        """Ensure the call to delivery_queue.get() occurs, and with
+        block=True.  Raises a Queue.Empty exception.
+        """
+        exception_causing_exit = Exception('Exit monitor_consumers() method')
+        self.mock_delivery_queue.get = Mock(
+            side_effect=[Queue.Empty(), exception_causing_exit])
+        try:
+            self.my_fdshim.monitor_consumers()
+        except Exception as err:
+            self.assertEqual(exception_causing_exit, err)
+        self.mock_delivery_queue.get.assert_called_with(block=True)
+
+    @patch('os.write')
+    def test_call_to_get_return_response_bundle(self, write_method):
+        """Ensure the call to get() occurs, and when the response bundle
+        is received from delivery_queue, that the response bundle is put
+        into queue_from_fdshim using put().
+
+        This method patches os.write to ensure that a '0' is written to the
+        _w file descriptor attribute of FDShim.
+        """
+        response_bundle = Mock()
+        exception_causing_exit = Exception('Exit monitor_consumers() method')
+        self.mock_delivery_queue.get = Mock(return_value=response_bundle)
+        write_method.side_effect = exception_causing_exit
+        try:
+            self.my_fdshim.monitor_consumers()
+        except Exception as err:
+            self.assertEqual(exception_causing_exit, err)
+        self.mock_delivery_queue.get.assert_called_with(block=True)
+        self.mock_queue_from_fdshim.put.assert_called_with(
+            response_bundle)
+        write_method.assert_called_with(self.my_fdshim._w, '0')
+
+
+class TestConnection(ExtraAssertionsMixin, Case):
+
+    @patch('qpid.messaging.Connection')
+    def setUp(self, QpidConnection):
+        """Setup a Connection with sane connection parameters."""
+        if QPID_NOT_AVAILABLE:
+            raise SkipTest('qpid.messaging not installed')
+        self.connection_options = {'host': 'localhost',
+                                   'port': 5672,
+                                   'username': 'guest',
+                                   'password': 'guest',
+                                   'transport': 'tcp',
+                                   'timeout': 10,
+                                   'sasl_mechanisms': 'PLAIN'}
+        self.created_connection = Mock()
+        QpidConnection.establish = Mock(return_value=self.created_connection)
+        self.mock_qpid_connection = QpidConnection
+        self.my_connection = Connection(**self.connection_options)
+
+    def test_init_variables(self):
+        """Test that all init params are internally stored correctly
+        """
+        self.assertDictEqual(self.connection_options,
+                             self.my_connection.connection_options)
+        self.assertTrue(isinstance(self.my_connection.channels, list))
+        self.assertTrue(isinstance(self.my_connection._callbacks, dict))
+        self.mock_qpid_connection.establish.assert_called_with(
+            **self.connection_options)
+        internal_conn = self.my_connection._qpid_conn
+        self.assertTrue(self.created_connection is internal_conn)
+
+    def test_verify_connection_class_attributes(self):
+        """Verify that Channel class attribute is set correctly"""
+        self.assertEqual(Channel, Connection.Channel)
+
+    def test_get_qpid_connection(self):
+        """Test that get_qpid_connection returns the connection."""
+        mock_connection = Mock()
+        self.my_connection._qpid_conn = mock_connection
+        returned_connection = self.my_connection.get_qpid_connection()
+        self.assertTrue(mock_connection is returned_connection)
+
+    def test_close_channel_exists(self):
+        """Test that calling close_channel() with a valid channel removes
+        the channel from self.channels and sets channel.connection to None.
+        """
+        mock_channel = Mock()
+        self.my_connection.channels = [mock_channel]
+        mock_channel.connection = True
+        self.my_connection.close_channel(mock_channel)
+        self.assertEqual(self.my_connection.channels, [])
+        self.assertTrue(mock_channel.connection is None)
+
+    def test_close_channel_does_not_exist(self):
+        """Test that calling close_channel() with an invalid channel does
+        not raise a ValueError and sets channel.connection to None.
+        """
+        self.my_connection.channels = Mock()
+        self.my_connection.channels.remove = Mock(side_effect=ValueError())
+        mock_channel = Mock()
+        mock_channel.connection = True
+        self.my_connection.close_channel(mock_channel)
+        self.assertTrue(mock_channel.connection is None)
+
+
+class TestChannel(ExtraAssertionsMixin, Case):
+
+    @skip_if_not_module('qpidtoollibs')
+    @patch('qpidtoollibs.BrokerAgent')
+    def setUp(self, mock_BrokerAgent):
+        """Set up objects for use in testing a Channel.
+
+        Create a mock Channel, and all associated mock objects."""
+        if QPID_NOT_AVAILABLE:
+            raise SkipTest('qpid.messaging not installed')
+        self.mock_connection = Mock()
+        self.mock_qpid_connection = Mock()
+        self.mock_qpid_session = Mock()
+        self.mock_qpid_connection.session = \
+            Mock(return_value=self.mock_qpid_session)
+        self.mock_connection.get_qpid_connection = \
+            Mock(return_value=self.mock_qpid_connection)
+        self.mock_transport = Mock()
+        self.mock_delivery_queue = Mock()
+        self.mock_broker = Mock()
+        self.mock_Message = Mock()
+        self.mock_BrokerAgent = mock_BrokerAgent
+        mock_BrokerAgent.return_value = self.mock_broker
+        self.my_channel = Channel(self.mock_connection,
+                                  self.mock_transport,
+                                  self.mock_delivery_queue)
+        self.my_channel.Message = self.mock_Message
+
+    def test_verify_QoS_class_attribute(self):
+        """Verify that the class attribute QoS refers to the QoS object"""
+        self.assertTrue(QoS is Channel.QoS)
+
+    def test_verify_Message_class_attribute(self):
+        """Verify that the class attribute Message refers to the Message
+        object
+        """
+        self.assertTrue(Message is Channel.Message)
+
+    def test_body_encoding_class_attribute(self):
+        """Verify that the class attribute body_encoding is set to base64"""
+        self.assertEqual('base64', Channel.body_encoding)
+
+    def test_codecs_class_attribute(self):
+        """Verify that the codecs class attribute has a correct key and
+        value
+        """
+        self.assertTrue(isinstance(Channel.codecs, dict))
+        self.assertTrue('base64' in Channel.codecs)
+        self.assertTrue(isinstance(Channel.codecs['base64'], Base64))
+
+    def test_delivery_tags(self):
+        """Test that _delivery_tags is using itertools"""
+        self.assertTrue(isinstance(Channel._delivery_tags, count))
+
+    def test_init_variables(self):
+        """Test init variables"""
+        self.assertTrue(self.mock_connection is self.my_channel.connection)
+        self.assertTrue(self.mock_transport is self.my_channel.transport)
+        self.assertTrue(self.mock_delivery_queue is
+                        self.my_channel.delivery_queue)
+        self.assertTrue(isinstance(self.my_channel._tag_to_queue, dict))
+        self.assertTrue(isinstance(self.my_channel._consumer_threads, dict))
+        self.assertTrue(self.mock_qpid_session is
+                        self.my_channel._qpid_session)
+        self.assertTrue(self.mock_broker is self.my_channel._broker)
+        self.assertTrue(self.my_channel._qos is None)
+        self.assertTrue(isinstance(self.my_channel._consumers, set))
+        self.assertFalse(self.my_channel.closed)
+        self.mock_connection.get_qpid_connection.assert_called_with()
+        self.mock_qpid_connection.session.assert_called_with()
+        self.mock_BrokerAgent.assert_called_with(self.mock_qpid_connection)
+
+    def test_get(self):
+        """Test _get() for return value from call to receiver, and check
+        that receiver has closed() called on it.
+        """
+        mock_queue = Mock()
+        mock_rx = Mock()
+        mock_message = Mock()
+        mock_rx.fetch.return_value = mock_message
+        self.mock_qpid_session.receiver.return_value = mock_rx
+        result = self.my_channel._get(mock_queue)
+        self.mock_qpid_session.receiver.assert_called_with(mock_queue)
+        mock_rx.close.assert_called_with()
+        self.assertTrue(mock_message is result)
+
+    @patch('qpid.messaging.Message')
+    def test_put_queue(self, mock_qpid_Message_obj):
+        """Test putting a messages directly into a queue."""
+        mock_routing_key = 'routingkey'
+        mock_message = Mock()
+        mock_sender = Mock()
+        mock_new_qpid_message_obj = Mock()
+        self.mock_qpid_session.sender.return_value = mock_sender
+        mock_qpid_Message_obj.return_value = mock_new_qpid_message_obj
+        self.my_channel._put(mock_routing_key, mock_message)
+        address_string = '%s; {assert: always, node: {type: queue}}' % \
+                         mock_routing_key
+        self.mock_qpid_session.sender.assert_called_with(address_string)
+        mock_qpid_Message_obj.assert_called_with(content=mock_message,
+                                                 subject=None)
+        mock_sender.send.assert_called_with(mock_new_qpid_message_obj,
+                                            sync=True)
+        mock_sender.close.assert_called_with()
+
+    @patch('qpid.messaging.Message')
+    def test_put_exchange(self, mock_qpid_Message_obj):
+        """Test putting a message directly into an exchange."""
+        mock_routing_key = 'routingkey'
+        mock_exchange_name = 'myexchange'
+        mock_message = Mock()
+        mock_sender = Mock()
+        mock_new_qpid_message_obj = Mock()
+        self.mock_qpid_session.sender.return_value = mock_sender
+        mock_qpid_Message_obj.return_value = mock_new_qpid_message_obj
+        self.my_channel._put(mock_routing_key, mock_message,
+                             mock_exchange_name)
+        address_string = '%s/%s; {assert: always, node: {type: topic}}' % \
+                         (mock_exchange_name, mock_routing_key)
+        self.mock_qpid_session.sender.assert_called_with(address_string)
+        mock_qpid_Message_obj.assert_called_with(content=mock_message,
+                                                 subject=mock_routing_key)
+        mock_sender.send.assert_called_with(mock_new_qpid_message_obj,
+                                            sync=True)
+        mock_sender.close.assert_called_with()
+
+    def test_purge(self):
+        """Test purging a queue that has messages, and verify the return
+        value.
+        """
+        message_count = 5
+        mock_queue = Mock()
+        mock_queue_to_purge = Mock()
+        mock_queue_to_purge.values = {'msgDepth': message_count}
+        self.mock_broker.getQueue.return_value = mock_queue_to_purge
+        result = self.my_channel._purge(mock_queue)
+        self.mock_broker.getQueue.assert_called_with(mock_queue)
+        mock_queue_to_purge.purge.assert_called_with(message_count)
+        self.assertEqual(message_count, result)
+
+    def test_size(self):
+        """Test getting the number of messages in a queue specified by
+        name and returning them.
+        """
+        message_count = 5
+        mock_queue = Mock()
+        mock_queue_to_check = Mock()
+        mock_queue_to_check.values = {'msgDepth': message_count}
+        self.mock_broker.getQueue.return_value = mock_queue_to_check
+        result = self.my_channel._size(mock_queue)
+        self.mock_broker.getQueue.assert_called_with(mock_queue)
+        self.assertEqual(message_count, result)
+
+    def test_delete(self):
+        """Test deleting a queue calls purge and delQueue with queue name"""
+        mock_queue = Mock()
+        self.my_channel._purge = Mock()
+        result = self.my_channel._delete(mock_queue)
+        self.my_channel._purge.assert_called_with(mock_queue)
+        self.mock_broker.delQueue.assert_called_with(mock_queue)
+        self.assertTrue(result is None)
+
+    def test_has_queue_true(self):
+        """Test checking if a queue exists, and it does"""
+        mock_queue = Mock()
+        self.mock_broker.getQueue.return_value = True
+        result = self.my_channel._has_queue(mock_queue)
+        self.assertTrue(result)
+
+    def test_has_queue_false(self):
+        """Test checking if a queue exists, and it does not"""
+        mock_queue = Mock()
+        self.mock_broker.getQueue.return_value = False
+        result = self.my_channel._has_queue(mock_queue)
+        self.assertFalse(result)
+
+    @patch('amqp.protocol.queue_declare_ok_t')
+    def test_queue_declare_with_exception_raised(self,
+                                                 mock_queue_declare_ok_t):
+        """Test declare_queue, where an exception is raised and silenced"""
+        mock_queue = Mock()
+        mock_passive = Mock()
+        mock_durable = Mock()
+        mock_exclusive = Mock()
+        mock_auto_delete = Mock()
+        mock_nowait = Mock()
+        mock_arguments = Mock()
+        mock_msg_count = Mock()
+        mock_queue.startswith.return_value = False
+        mock_queue.endswith.return_value = False
+        options = {'passive': mock_passive,
+                   'durable': mock_durable,
+                   'exclusive': mock_exclusive,
+                   'auto-delete': mock_auto_delete,
+                   'arguments': mock_arguments,
+                   'qpid.auto_delete_timeout': 3}
+        mock_consumer_count = Mock()
+        mock_return_value = Mock()
+        values_dict = {'msgDepth': mock_msg_count,
+                       'consumerCount': mock_consumer_count}
+        mock_queue_data = Mock()
+        mock_queue_data.values = values_dict
+        exception_to_raise = Exception('The foo object already exists.')
+        self.mock_broker.addQueue.side_effect = exception_to_raise
+        self.mock_broker.getQueue.return_value = mock_queue_data
+        mock_queue_declare_ok_t.return_value = mock_return_value
+        result = self.my_channel.queue_declare(mock_queue,
+                                               passive=mock_passive,
+                                               durable=mock_durable,
+                                               exclusive=mock_exclusive,
+                                               auto_delete=mock_auto_delete,
+                                               nowait=mock_nowait,
+                                               arguments=mock_arguments,
+                                               )
+        self.mock_broker.addQueue.assert_called_with(mock_queue,
+                                                     options=options)
+        mock_queue_declare_ok_t.assert_called_with(mock_queue,
+                                                   mock_msg_count,
+                                                   mock_consumer_count)
+        self.assertTrue(mock_return_value is result)
+
+    def test_queue_declare_set_ring_policy_for_celeryev(self):
+        """Test declare_queue sets ring_policy for celeryev"""
+        mock_queue = Mock()
+        mock_queue.startswith.return_value = True
+        mock_queue.endswith.return_value = False
+        expected_default_options = {'passive': False,
+                                    'durable': False,
+                                    'exclusive': False,
+                                    'auto-delete': True,
+                                    'arguments': None,
+                                    'qpid.auto_delete_timeout': 3,
+                                    'qpid.policy_type': 'ring'}
+        mock_msg_count = Mock()
+        mock_consumer_count = Mock()
+        values_dict = {'msgDepth': mock_msg_count,
+                       'consumerCount': mock_consumer_count}
+        mock_queue_data = Mock()
+        mock_queue_data.values = values_dict
+        self.mock_broker.addQueue.return_value = None
+        self.mock_broker.getQueue.return_value = mock_queue_data
+        self.my_channel.queue_declare(mock_queue)
+        mock_queue.startswith.assert_called_with('celeryev')
+
+    def test_queue_declare_set_ring_policy_for_pidbox(self):
+        """Test declare_queue sets ring_policy for pidbox"""
+        mock_queue = Mock()
+        mock_queue.startswith.return_value = False
+        mock_queue.endswith.return_value = True
+        expected_default_options = {'passive': False,
+                                    'durable': False,
+                                    'exclusive': False,
+                                    'auto-delete': True,
+                                    'arguments': None,
+                                    'qpid.auto_delete_timeout': 3,
+                                    'qpid.policy_type': 'ring'}
+        mock_msg_count = Mock()
+        mock_consumer_count = Mock()
+        values_dict = {'msgDepth': mock_msg_count,
+                       'consumerCount': mock_consumer_count}
+        mock_queue_data = Mock()
+        mock_queue_data.values = values_dict
+        self.mock_broker.addQueue.return_value = None
+        self.mock_broker.getQueue.return_value = mock_queue_data
+        self.my_channel.queue_declare(mock_queue)
+        mock_queue.endswith.assert_called_with('pidbox')
+
+    def test_queue_declare_ring_policy_not_set_as_expected(self):
+        """Test declare_queue does not set ring_policy as expected"""
+        mock_queue = Mock()
+        mock_queue.startswith.return_value = False
+        mock_queue.endswith.return_value = False
+        expected_default_options = {'passive': False,
+                                    'durable': False,
+                                    'exclusive': False,
+                                    'auto-delete': True,
+                                    'arguments': None,
+                                    'qpid.auto_delete_timeout': 3}
+        mock_msg_count = Mock()
+        mock_consumer_count = Mock()
+        values_dict = {'msgDepth': mock_msg_count,
+                       'consumerCount': mock_consumer_count}
+        mock_queue_data = Mock()
+        mock_queue_data.values = values_dict
+        self.mock_broker.addQueue.return_value = None
+        self.mock_broker.getQueue.return_value = mock_queue_data
+        self.my_channel.queue_declare(mock_queue)
+        mock_queue.startswith.assert_called_with('celeryev')
+        mock_queue.endswith.assert_called_with('pidbox')
+
+    def test_queue_declare_test_defaults(self):
+        """Test declare_queue defaults"""
+        mock_queue = Mock()
+        mock_queue.startswith.return_value = False
+        mock_queue.endswith.return_value = False
+        expected_default_options = {'passive': False,
+                                    'durable': False,
+                                    'exclusive': False,
+                                    'auto-delete': True,
+                                    'arguments': None,
+                                    'qpid.auto_delete_timeout': 3}
+        mock_msg_count = Mock()
+        mock_consumer_count = Mock()
+        values_dict = {'msgDepth': mock_msg_count,
+                       'consumerCount': mock_consumer_count}
+        mock_queue_data = Mock()
+        mock_queue_data.values = values_dict
+        self.mock_broker.addQueue.return_value = None
+        self.mock_broker.getQueue.return_value = mock_queue_data
+        self.my_channel.queue_declare(mock_queue)
+        self.mock_broker.addQueue.assert_called_with(
+            mock_queue,
+            options=expected_default_options)
+
+    def test_queue_declare_raises_exception_not_silenced(self):
+        """Test declare_queue, raise an exception that is raised and not silenced"""
+        unique_exception = Exception('This exception should not be silenced')
+        mock_queue = Mock()
+        self.mock_broker.addQueue.side_effect = unique_exception
+        self.assertRaises(unique_exception.__class__,
+                          self.my_channel.queue_declare,
+                          mock_queue)
+        self.mock_broker.addQueue.assert_called_once()
+
+    def test_queue_delete_if_empty_param(self):
+        """Test the deletion of a queue with if_empty=True"""
+        mock_queue = Mock()
+        self.my_channel._has_queue = Mock(return_value=True)
+        self.my_channel._size = Mock(return_value=5)
+        result = self.my_channel.queue_delete(mock_queue, if_empty=True)
+        self.my_channel._has_queue.assert_called_with(mock_queue)
+        self.my_channel._size.assert_called_with(mock_queue)
+        self.assertTrue(result is None)
+
+    def test_queue_delete_if_unused_param(self):
+        """Test the deletion of a queue with if_unused=True"""
+        mock_queue = Mock()
+        mock_queue_obj = Mock()
+        mock_queue_attributes = {'consumerCount': 5}
+        mock_queue_obj.getAttributes.return_value = mock_queue_attributes
+        self.my_channel._has_queue = Mock(return_value=True)
+        self.my_channel._size = Mock(return_value=5)
+        self.mock_broker.getQueue.return_value = mock_queue_obj
+        result = self.my_channel.queue_delete(mock_queue, if_unused=True)
+        self.assertTrue(result is None)
+
+    def test_queue_delete(self):
+        """Test the deletion of a queue"""
+        mock_queue = Mock()
+        mock_queue_obj = Mock()
+        mock_queue_attributes = {'consumerCount': 5}
+        mock_queue_obj.getAttributes.return_value = mock_queue_attributes
+        self.my_channel._has_queue = Mock(return_value=True)
+        self.my_channel._size = Mock(return_value=5)
+        self.my_channel._delete = Mock()
+        self.mock_broker.getQueue.return_value = mock_queue_obj
+        result = self.my_channel.queue_delete(mock_queue)
+        self.my_channel._delete.assert_called_with(mock_queue)
+        self.assertTrue(result is None)
+
+    def test_exchange_declare_raises_exception_and_silenced(self):
+        """Create exchange where an exception is raised and then silenced"""
+        self.mock_broker.addExchange.side_effect = \
+            Exception('The foo object already exists.')
+        self.my_channel.exchange_declare()
+
+    def test_exchange_declare_raises_exception_not_silenced(self):
+        """Create Exchange where an exception is raised and not silenced"""
+        unique_exception = Exception('This exception should not be silenced')
+        self.mock_broker.addExchange.side_effect = unique_exception
+        self.assertRaises(unique_exception.__class__,
+                          self.my_channel.exchange_declare)
+
+    def test_exchange_declare(self):
+        """Create Exchange where an exception is NOT raised"""
+        mock_exchange = Mock()
+        mock_type = Mock()
+        mock_durable = Mock()
+        options = {'durable': mock_durable}
+        result = self.my_channel.exchange_declare(mock_exchange,
+                                                  mock_type,
+                                                  mock_durable)
+        self.mock_broker.addExchange.assert_called_with(mock_type,
+                                                        mock_exchange,
+                                                        options)
+        self.assertTrue(result is None)
+
+    def test_exchange_delete(self):
+        """Test the deletion of an exchange by name"""
+        mock_exchange = Mock()
+        result = self.my_channel.exchange_delete(mock_exchange)
+        self.mock_broker.delExchange.assert_called_with(mock_exchange)
+        self.assertTrue(result is None)
+
+    def test_queue_bind(self):
+        """Test binding a queue to an exchange using a routing key"""
+        mock_queue = Mock()
+        mock_exchange = Mock()
+        mock_routing_key = Mock()
+        self.my_channel.queue_bind(mock_queue,
+                                   mock_exchange,
+                                   mock_routing_key)
+        self.mock_broker.bind.assert_called_with(mock_exchange,
+                                                 mock_queue,
+                                                 mock_routing_key)
+
+    def test_queue_unbind(self):
+        """Test unbinding a queue from an exchange using a routing key"""
+        mock_queue = Mock()
+        mock_exchange = Mock()
+        mock_routing_key = Mock()
+        self.my_channel.queue_unbind(mock_queue,
+                                     mock_exchange,
+                                     mock_routing_key)
+        self.mock_broker.unbind.assert_called_with(mock_exchange,
+                                                   mock_queue,
+                                                   mock_routing_key)
+
+    def test_queue_purge(self):
+        """Test purging a queue by name"""
+        mock_queue = Mock()
+        purge_result = Mock()
+        self.my_channel._purge = Mock(return_value=purge_result)
+        result = self.my_channel.queue_purge(mock_queue)
+        self.my_channel._purge.assert_called_with(mock_queue)
+        self.assertTrue(purge_result is result)
+
+    def test_basic_get_happy_path(self):
+        """Test a basic_get with the most common case"""
+        mock_queue = Mock()
+        mock_qpid_message = Mock()
+        new_message = Mock()
+        self.my_channel._get = Mock(return_value=mock_qpid_message)
+        self.mock_Message.return_value = new_message
+        result = self.my_channel.basic_get(mock_queue)
+        self.mock_qpid_session.acknowledge.assert_called_with(
+            message=mock_qpid_message)
+        self.assertTrue(new_message is result)
+
+    def test_basic_get_no_ack_equals_True(self):
+        """Test a basic_get where no_ack equals True"""
+        mock_queue = Mock()
+        mock_qpid_message = Mock()
+        new_message = Mock()
+        self.my_channel._get = Mock(return_value=mock_qpid_message)
+        self.mock_Message.return_value = new_message
+        result = self.my_channel.basic_get(mock_queue, no_ack=True)
+        self.assertEqual(self.mock_qpid_session.acknowledge.call_count, 0)
+        self.assertTrue(new_message is result)
+
+    def test_basic_get_raises_Empty(self):
+        """Test a basic_get where _get() raises an Empty exception"""
+        mock_queue = Mock()
+        self.my_channel._get = Mock(side_effect=kombu.five.Empty)
+        result = self.my_channel.basic_get(mock_queue)
+        self.assertEqual(self.my_channel.Message.call_count, 0)
+        self.assertTrue(result is None)
+
+    @patch('kombu.transport.qpid.Channel.qos')
+    def test_basic_ack(self, mock_qos):
+        """Test that basic_ack calls the QoS object properly"""
+        mock_delivery_tag = Mock()
+        self.my_channel.basic_ack(mock_delivery_tag)
+        mock_qos.ack.assert_called_with(mock_delivery_tag)
+
+    @patch('kombu.transport.qpid.Channel.qos')
+    def test_basic_reject(self, mock_qos):
+        """Test that basic_reject calls the QoS object properly"""
+        mock_delivery_tag = Mock()
+        mock_requeue_value = Mock()
+        self.my_channel.basic_reject(mock_delivery_tag, mock_requeue_value)
+        mock_qos.reject.assert_called_with(mock_delivery_tag,
+                                           requeue=mock_requeue_value)
+
+    @patch('kombu.transport.qpid.FDShimThread')
+    def test_basic_consume(self, mock_FDShimThread):
+        """Test a basic_consume() to fetch a message."""
+        mock_queue = Mock()
+        mock_no_ack = False
+        mock_callback = Mock()
+        mock_consumer_tag = Mock()
+        self.mock_connection._callbacks = {}
+        mock_my_thread = Mock()
+        mock_FDShimThread.return_value = mock_my_thread
+        self.my_channel.basic_consume(mock_queue, mock_no_ack,
+                                      mock_callback, mock_consumer_tag)
+        self.assertTrue(mock_consumer_tag in self.my_channel._tag_to_queue)
+        queue_reference = self.my_channel._tag_to_queue[mock_consumer_tag]
+        self.assertTrue(queue_reference is mock_queue)
+        self.assertTrue(mock_queue in self.mock_connection._callbacks)
+        _callback_reference = self.mock_connection._callbacks[mock_queue]
+        if not hasattr(_callback_reference, '__call__'):
+            self.fail('Callback stored must be callable')
+        self.basic_consume_callback_helper(_callback_reference,
+                                           mock_callback)
+        self.assertTrue(mock_consumer_tag in self.my_channel._consumers)
+        mock_FDShimThread.assert_called_with(
+            self.mock_connection.get_qpid_connection,
+            mock_queue,
+            self.mock_delivery_queue)
+        self.assertTrue(mock_queue in self.my_channel._consumer_threads)
+        my_thread_reference = self.my_channel._consumer_threads[mock_queue]
+        self.assertTrue(mock_my_thread is my_thread_reference)
+        self.assertTrue(mock_my_thread.daemon)
+        mock_my_thread.start.assert_called_with()
+
+    @patch('kombu.transport.qpid.Channel.qos')
+    def basic_consume_callback_helper(self, new_callback,
+                                      original_callback,
+                                      mock_qos):
+        """Test the dynamically built callback inside basic_consume()"""
+        mock_qpid_message = Mock()
+        mock_raw_message = Mock()
+        new_mock_message = Mock()
+        new_mock_delivery_tag = Mock()
+        original_callback_result = Mock()
+        original_callback.return_value = original_callback_result
+        new_mock_message.delivery_tag = new_mock_delivery_tag
+        mock_qpid_message.content = mock_raw_message
+        self.mock_Message.return_value = new_mock_message
+        result = new_callback(mock_qpid_message)
+        self.mock_Message.assert_called_with(self.my_channel,
+                                             mock_raw_message)
+        mock_qos.append.assert_called_with(mock_qpid_message,
+                                           new_mock_delivery_tag)
+        original_callback.assert_called_with(new_mock_message)
+        self.assertTrue(original_callback_result is result)
+
+    def test_basic_cancel(self):
+        """Test basic_cancel() by consumer tag"""
+        mock_consumer_tag = Mock()
+        mock_queue = Mock()
+        mock_consumer_thread = Mock()
+        self.my_channel._consumers = set([mock_consumer_tag])
+        self.my_channel._tag_to_queue = Mock()
+        self.my_channel._tag_to_queue.pop.return_value = mock_queue
+        self.my_channel._consumer_threads = Mock()
+        self.my_channel._consumer_threads.pop.return_value = \
+            mock_consumer_thread
+        self.my_channel.basic_cancel(mock_consumer_tag)
+        self.assertTrue(mock_consumer_tag not in self.my_channel._consumers)
+        self.my_channel._tag_to_queue.pop.assert_called_with(
+            mock_consumer_tag, None)
+        self.my_channel._consumer_threads.pop.assert_called_with(
+            mock_queue, None)
+        mock_consumer_thread.kill.assert_called_once()
+        self.mock_connection._callbacks.pop.assert_called_once(mock_queue,
+                                                               None)
+
+    @patch('kombu.transport.qpid.Channel.basic_cancel')
+    def test_close(self, mock_basic_cancel):
+        """Test close() on Channel"""
+        mock_consumer1 = Mock()
+        mock_consumer2 = Mock()
+        self.my_channel._consumers = set([mock_consumer1, mock_consumer2])
+        self.my_channel.closed = False
+        self.my_channel.close()
+        self.assertTrue(self.my_channel.closed)
+        mock_basic_cancel.assert_any_call(mock_consumer2)
+        mock_basic_cancel.assert_any_call(mock_consumer1)
+        self.mock_connection.close_channel.assert_called_once(
+            self.my_channel)
+        self.mock_qpid_session.close.assert_called_once()
+        self.mock_broker.close.assert_called_once()
+
+    def test_qos_manager_is_none(self):
+        """Test the qos property if the QoS object did not already exist"""
+        self.my_channel._qos = None
+        result = self.my_channel.qos
+        self.assertTrue(isinstance(result, QoS))
+        self.assertEqual(result, self.my_channel._qos)
+
+    def test_qos_manager_already_exists(self):
+        """Test the qos property if the QoS object already exists"""
+        mock_existing_qos = Mock()
+        self.my_channel._qos = mock_existing_qos
+        result = self.my_channel.qos
+        self.assertTrue(mock_existing_qos is result)
+
+    @patch('kombu.transport.qpid.Channel.qos')
+    def test_basic_qos(self, mock_qos):
+        """Verify the basic_qos() sets prefetch_count on the QoS object"""
+        mock_prefetch_count = Mock()
+        self.my_channel.basic_qos(mock_prefetch_count)
+        self.assertTrue(mock_prefetch_count is mock_qos.prefetch_count)
+
+    def test_prepare_message(self):
+        """Test that prepare_message() returns the correct result"""
+        mock_body = Mock()
+        mock_priority = Mock()
+        mock_content_encoding = Mock()
+        mock_content_type = Mock()
+        mock_header1 = Mock()
+        mock_header2 = Mock()
+        mock_properties1 = Mock()
+        mock_properties2 = Mock()
+        headers = {'header1': mock_header1, 'header2': mock_header2}
+        properties = {'properties1': mock_properties1,
+                      'properties2': mock_properties2}
+        result = self.my_channel.prepare_message(
+            mock_body,
+            priority=mock_priority,
+            content_type=mock_content_type,
+            content_encoding=mock_content_encoding,
+            headers=headers,
+            properties=properties)
+        self.assertTrue(mock_body is result['body'])
+        self.assertTrue(mock_content_encoding is result['content-encoding'])
+        self.assertTrue(mock_content_type is result['content-type'])
+        self.assertDictEqual(headers, result['headers'])
+        self.assertDictContainsSubset(properties, result['properties'])
+        self.assertTrue(mock_priority is
+                        result['properties']['delivery_info']['priority'])
+
+    @patch('__builtin__.buffer')
+    @patch('kombu.transport.qpid.Channel.body_encoding')
+    @patch('kombu.transport.qpid.Channel.encode_body')
+    @patch('kombu.transport.qpid.Channel._put')
+    def test_basic_publish(self, mock_put,
+                           mock_encode_body,
+                           mock_body_encoding,
+                           mock_buffer):
+        """Test basic_publish()"""
+        mock_original_body = Mock()
+        mock_encoded_body = 'this is my encoded body'
+        mock_message = {'body': mock_original_body,
+                        'properties': {'delivery_info': {}}}
+        mock_encode_body.return_value = (mock_encoded_body,
+                                         mock_body_encoding)
+        mock_exchange = Mock()
+        mock_routing_key = Mock()
+        mock_encoded_buffered_body = Mock()
+        mock_buffer.return_value = mock_encoded_buffered_body
+        self.my_channel.basic_publish(mock_message,
+                                      mock_exchange,
+                                      mock_routing_key)
+        mock_encode_body.assert_called_once(mock_original_body,
+                                            mock_body_encoding)
+        mock_buffer.assert_called_once(mock_encode_body)
+        self.assertTrue(mock_message['body'] is mock_encoded_buffered_body)
+        self.assertTrue(mock_message['properties']['body_encoding'] is
+                        mock_body_encoding)
+        self.assertTrue(
+            isinstance(mock_message['properties']['delivery_tag'], int))
+        self.assertTrue(mock_message['properties']['delivery_info']
+                        ['exchange'] is mock_exchange)
+        self.assertTrue(
+            mock_message['properties']['delivery_info']['routing_key'] is
+            mock_routing_key)
+        mock_put.assert_called_with(mock_routing_key,
+                                    mock_message,
+                                    mock_exchange)
+
+    @patch('kombu.transport.qpid.Channel.codecs')
+    def test_encode_body_expected_encoding(self, mock_codecs):
+        """Test if encode_body() works when encoding is set correctly"""
+        mock_body = Mock()
+        mock_encoder = Mock()
+        mock_encoded_result = Mock()
+        mock_codecs.get.return_value = mock_encoder
+        mock_encoder.encode.return_value = mock_encoded_result
+        result = self.my_channel.encode_body(mock_body, encoding='base64')
+        expected_result = (mock_encoded_result, 'base64')
+        self.assertEqual(expected_result, result)
+
+    @patch('kombu.transport.qpid.Channel.codecs')
+    def test_encode_body_not_expected_encoding(self, mock_codecs):
+        """Test if encode_body() works when encoding is not set correctly"""
+        mock_body = Mock()
+        result = self.my_channel.encode_body(mock_body,
+                                             encoding=None)
+        expected_result = (mock_body, None)
+        self.assertEqual(expected_result, result)
+
+    @patch('kombu.transport.qpid.Channel.codecs')
+    def test_decode_body_expected_encoding(self, mock_codecs):
+        """Test if decode_body() works when encoding is set correctly"""
+        mock_body = Mock()
+        mock_decoder = Mock()
+        mock_decoded_result = Mock()
+        mock_codecs.get.return_value = mock_decoder
+        mock_decoder.decode.return_value = mock_decoded_result
+        result = self.my_channel.decode_body(mock_body, encoding='base64')
+        self.assertEqual(mock_decoded_result, result)
+
+    @patch('kombu.transport.qpid.Channel.codecs')
+    def test_decode_body_not_expected_encoding(self, mock_codecs):
+        """Test if decode_body() works when encoding is not set correctly"""
+        mock_body = Mock()
+        result = self.my_channel.decode_body(mock_body, encoding=None)
+        self.assertEqual(mock_body, result)
+
+    def test_typeof_exchange_exists(self):
+        """Test that typeof() finds an exchange that already exists"""
+        mock_exchange = Mock()
+        mock_qpid_exchange = Mock()
+        mock_attributes = {}
+        mock_type = Mock()
+        mock_attributes['type'] = mock_type
+        mock_qpid_exchange.getAttributes.return_value = mock_attributes
+        self.mock_broker.getExchange.return_value = mock_qpid_exchange
+        result = self.my_channel.typeof(mock_exchange)
+        self.assertTrue(mock_type is result)
+
+    def test_typeof_exchange_does_not_exist(self):
+        """Test that typeof() finds an exchange that does not exists"""
+        mock_exchange = Mock()
+        mock_default = Mock()
+        self.mock_broker.getExchange.return_value = None
+        result = self.my_channel.typeof(mock_exchange, default=mock_default)
+        self.assertTrue(mock_default is result)
+
+
+class TestTransport(ExtraAssertionsMixin, Case):
+
+    def setUp(self):
+        """Creates a mock_client to be used in testing."""
+        if QPID_NOT_AVAILABLE:
+            raise SkipTest('qpid.messaging not installed')
+        self.mock_client = Mock()
+
+    @patch('kombu.transport.qpid.FDShim')
+    @patch('threading.Thread')
+    def test_init_variables(self, mock_thread, mock_FDShim):
+        """Test that all simple init params are internally stored
+        correctly
+        """
+        new_fdshim = Mock()
+        mock_FDShim.return_value = new_fdshim
+        new_thread = Mock()
+        mock_thread.return_value = new_thread
+        my_transport = Transport(self.mock_client)
+        self.assertTrue(my_transport.client is self.mock_client)
+        self.assertTrue(
+            isinstance(my_transport.queue_from_fdshim,  Queue.Queue))
+        self.assertTrue(
+            isinstance(my_transport.delivery_queue, Queue.Queue))
+        mock_FDShim.assert_called_with(my_transport.queue_from_fdshim,
+                                       my_transport.delivery_queue)
+        self.assertTrue(new_fdshim is my_transport.fd_shim)
+        mock_thread.assert_called_with(
+            target=my_transport.fd_shim.monitor_consumers)
+        self.assertTrue(new_thread.daemon)
+        new_thread.start.assert_called_with()
+
+    def test_verify_Connection_attribute(self):
+        """Verify that class attribute Connection refers to the connection
+        object
+        """
+        self.assertTrue(Connection is Transport.Connection)
+
+    def test_verify_default_port(self):
+        """Verify that the class attribute default_port refers to the 5672
+        properly
+        """
+        self.assertEqual(5672, Transport.default_port)
+
+    def test_verify_polling_disabled(self):
+        """Verify that polling is disabled"""
+        self.assertTrue(Transport.polling_interval is None)
+
+    def test_verify_supports_asynchronous_events(self):
+        """Verify that the Transport advertises that it supports
+        an asynchronous event model
+        """
+        self.assertTrue(Transport.supports_ev)
+
+    def test_verify_driver_type_and_name(self):
+        """Verify that the driver and type are correctly labeled on the
+        class
+        """
+        self.assertEqual('qpid', Transport.driver_type)
+        self.assertEqual('qpid', Transport.driver_name)
+
+    def test_register_with_event_loop(self):
+        """Test that the file descriptor to monitor, and the on_readable
+        callbacks properly register with the event loop
+        """
+        my_transport = Transport(self.mock_client)
+        mock_connection = Mock()
+        mock_loop = Mock()
+        my_transport.register_with_event_loop(mock_connection, mock_loop)
+        mock_loop.add_reader.assert_called_with(my_transport.fd_shim.r,
+                                                my_transport.on_readable,
+                                                mock_connection, mock_loop)
+
+    def test_establish_connection_no_ssl(self):
+        """Test that a call to establish connection creates a connection
+        object with sane parameters and returns it.
+        """
+        self.mock_client.ssl = False
+        self.mock_client.transport_options = []
+        my_transport = Transport(self.mock_client)
+        new_connection = Mock()
+        my_transport.Connection = Mock(return_value=new_connection)
+        my_transport.establish_connection()
+        my_transport.Connection.assert_called_once()
+        self.assertTrue(new_connection.client is self.mock_client)
+
+    def test_close_connection(self):
+        """Test that close_connection calls close on each channel in the
+        list of channels on the connection object.
+        """
+        my_transport = Transport(self.mock_client)
+        mock_connection = Mock()
+        mock_channel_1 = Mock()
+        mock_channel_2 = Mock()
+        mock_connection.channels = [mock_channel_1, mock_channel_2]
+        my_transport.close_connection(mock_connection)
+        mock_channel_1.close.assert_called_with()
+        mock_channel_2.close.assert_called_with()
+
+    def test_drain_events_get_raises_empty_no_timeout(self):
+        """Test drain_events() to ensure that a socket.timeout is raised
+        once the get() method on queue_from_fdshim raises a Queue.Empty.
+        """
+        my_transport = Transport(self.mock_client)
+        my_transport.queue_from_fdshim = Mock()
+        my_transport.queue_from_fdshim.get = Mock(side_effect=Queue.Empty())
+        mock_connection = Mock()
+        self.assertRaises(socket.timeout, my_transport.drain_events,
+                          mock_connection)
+
+    def test_drain_events_and_raise_timeout(self):
+        """Test drain_events() drains properly and also exits after the
+        timeout is reached even if the queue isn't empty.
+        """
+        my_transport = Transport(self.mock_client)
+        my_transport.queue_from_fdshim = Mock()
+        mock_queue = Mock()
+        mock_message = Mock()
+
+        def sleep_and_return_message(block, timeout):
+            time.sleep(0.5)
+            return (mock_queue, mock_message)
+        my_transport.queue_from_fdshim.get = sleep_and_return_message
+        mock_connection = Mock()
+        mock_callback = Mock()
+        mock_connection._callbacks = {mock_queue: mock_callback}
+        self.assertRaises(socket.timeout, my_transport.drain_events,
+                          mock_connection, timeout=2)
+        mock_callback.assert_called_with(mock_message)
+
+    def test_create_channel(self):
+        """Test that a Channel is created, and appended to the list of
+        channels the connection maintains.
+        """
+        my_transport = Transport(self.mock_client)
+        mock_connection = Mock()
+        mock_new_channel = Mock()
+        mock_connection.Channel.return_value = mock_new_channel
+        returned_channel = my_transport.create_channel(mock_connection)
+        self.assertTrue(mock_new_channel is returned_channel)
+        mock_connection.Channel.assert_called_with(
+            mock_connection,
+            my_transport,
+            my_transport.delivery_queue)
+        mock_connection.channels.append.assert_called_with(mock_new_channel)
+
+    @patch('os.read')
+    def test_on_readable(self, mock_os_read):
+        """Test on_readable() reads an available message."""
+        my_transport = Transport(self.mock_client)
+        mock_drain_events = Mock(side_effect=socket.timeout())
+        my_transport.drain_events = mock_drain_events
+        mock_connection = Mock()
+        mock_loop = Mock()
+        mock_os_read.return_value = '0'
+        result = my_transport.on_readable(mock_connection, mock_loop)
+        mock_os_read.assert_called_with(my_transport.fd_shim.r, 1)
+        mock_drain_events.assert_called_with(mock_connection)
+        self.assertTrue(result is None)
+
+    def test_default_connection_params(self):
+        """Test that the default_connection_params are correct"""
+        correct_params = {'userid': 'guest', 'password': 'guest',
+                          'port': 5672, 'virtual_host': '',
+                          'hostname': 'localhost',
+                          'sasl_mechanisms': 'PLAIN'}
+        my_transport = Transport(self.mock_client)
+        result_params = my_transport.default_connection_params
+        self.assertDictEqual(correct_params, result_params)
diff --git a/kombu/transport/__init__.py b/kombu/transport/__init__.py
index 10d62e9..c1d6868 100644
--- a/kombu/transport/__init__.py
+++ b/kombu/transport/__init__.py
@@ -68,6 +68,7 @@ TRANSPORT_ALIASES = {
     'zeromq': 'kombu.transport.zmq:Transport',
     'zmq': 'kombu.transport.zmq:Transport',
     'amqplib': 'kombu.transport.amqplib:Transport',
+    'qpid': 'kombu.transport.qpid:Transport',
 }
 
 _transport_cache = {}
diff --git a/kombu/transport/qpid.py b/kombu/transport/qpid.py
new file mode 100644
index 0000000..430da2f
--- /dev/null
+++ b/kombu/transport/qpid.py
@@ -0,0 +1,1716 @@
+"""
+kombu.transport.qpid
+=======================
+
+`Qpid`_ transport using `qpid-python`_ as the client and `qpid-tools`_ for
+broker management.
+
+.. _`Qpid`: http://qpid.apache.org/
+.. _`qpid-python`: http://pypi.python.org/pypi/qpid-python/
+.. _`qpid-tools`: http://pypi.python.org/pypi/qpid-tools/
+
+    .. admonition:: Install Dependencies
+
+        Run the command:
+
+        `pip install qpid-tools qpid-python`
+
+"""
+from __future__ import absolute_import
+
+"""Kombu transport using a Qpid broker as a message store."""
+
+import os
+import threading
+import Queue
+import socket
+import ssl
+import time
+
+from itertools import count
+
+import amqp.protocol
+
+try:
+    import qpidtoollibs
+except ImportError:  # pragma: no cover
+    qpidtoollibs = None     # noqa
+
+from kombu.five import Empty, items
+from kombu.log import get_logger
+from kombu.transport.virtual import Base64, Message
+from kombu.utils.compat import OrderedDict
+from kombu.transport import base
+
+
+logger = get_logger(__name__)
+
+
+##### Start Monkey Patching #####
+
+# This section applies two patches to qpid.messaging that are required for
+# correct operation.  Each patch fixes a bug.  See links to the bugs below:
+# https://issues.apache.org/jira/browse/QPID-5637
+# https://issues.apache.org/jira/browse/QPID-5557
+
+### Begin Monkey Patch 1 ###
+# https://issues.apache.org/jira/browse/QPID-5637
+
+#############################################################################
+#  _   _  ___ _____ _____
+# | \ | |/ _ \_   _| ____|
+# |  \| | | | || | |  _|
+# | |\  | |_| || | | |___
+# |_| \_|\___/ |_| |_____|
+#
+#If you have code that also uses qpid.messaging and imports kombu,
+# or causes this file to be imported, then you need to make sure that this
+# import occurs first.
+#
+# Failure to do this will cause the following exception:
+# AttributeError: 'Selector' object has no attribute '_current_pid'
+#
+# Fix this by importing this module prior to using qpid.messaging in other
+# code that also uses this module.
+#############################################################################
+
+
+# Imports for Monkey Patch 1
+try:
+    from qpid.selector import Selector
+except ImportError:  # pragma: no cover
+    Selector = None     # noqa
+import atexit
+
+
+# Prepare for Monkey Patch 1
+def default_monkey():  # pragma: no cover
+    Selector.lock.acquire()
+    try:
+        if Selector.DEFAULT is None:
+            sel = Selector()
+            atexit.register(sel.stop)
+            sel.start()
+            Selector.DEFAULT = sel
+            Selector._current_pid = os.getpid()
+        elif Selector._current_pid != os.getpid():
+            sel = Selector()
+            atexit.register(sel.stop)
+            sel.start()
+            Selector.DEFAULT = sel
+            Selector._current_pid = os.getpid()
+        return Selector.DEFAULT
+    finally:
+        Selector.lock.release()
+
+# Apply Monkey Patch 1
+
+try:
+    import qpid.selector
+    qpid.selector.Selector.default = staticmethod(default_monkey)
+except ImportError:  # pragma: no cover
+    pass
+
+### End Monkey Patch 1 ###
+
+### Begin Monkey Patch 2 ###
+# https://issues.apache.org/jira/browse/QPID-5557
+
+# Imports for Monkey Patch 2
+try:
+    from qpid.ops import ExchangeQuery, QueueQuery
+except ImportError:  # pragma: no cover
+    ExchangeQuery = None
+    QueueQuery = None
+
+try:
+    from qpid.messaging.exceptions import NotFound, AssertionFailed
+except ImportError:  # pragma: no cover
+    NotFound = None
+    AssertionFailed = None
+
+
+# Prepare for Monkey Patch 2
+def resolve_declare_monkey(self, sst, lnk, dir, action):  # pragma: no cover
+    declare = lnk.options.get("create") in ("always", dir)
+    assrt = lnk.options.get("assert") in ("always", dir)
+    requested_type = lnk.options.get("node", {}).get("type")
+
+    def do_resolved(type, subtype):
+        err = None
+        if type is None:
+            if declare:
+                err = self.declare(sst, lnk, action)
+            else:
+                err = NotFound(text="no such queue: %s" % lnk.name)
+        else:
+            if assrt:
+                expected = lnk.options.get("node", {}).get("type")
+                if expected and type != expected:
+                    err = AssertionFailed(
+                        text="expected %s, got %s" % (expected, type))
+            if err is None:
+                action(type, subtype)
+        if err:
+            tgt = lnk.target
+            tgt.error = err
+            del self._attachments[tgt]
+            tgt.closed = True
+            return
+
+    self.resolve(sst, lnk.name, do_resolved, node_type=requested_type,
+                 force=declare)
+
+
+def resolve_monkey(self, sst, name, action, force=False,
+                   node_type=None):  # pragma: no cover
+    if not force and not node_type:
+        try:
+            type, subtype = self.address_cache[name]
+            action(type, subtype)
+            return
+        except KeyError:
+            pass
+    args = []
+
+    def do_result(r):
+        args.append(r)
+
+    def do_action(r):
+        do_result(r)
+        er, qr = args
+        if node_type == "topic" and not er.not_found:
+            type, subtype = "topic", er.type
+        elif node_type == "queue" and qr.queue:
+            type, subtype = "queue", None
+        elif er.not_found and not qr.queue:
+            type, subtype = None, None
+        elif qr.queue:
+            type, subtype = "queue", None
+        else:
+            type, subtype = "topic", er.type
+        if type is not None:
+            self.address_cache[name] = (type, subtype)
+        action(type, subtype)
+
+    sst.write_query(ExchangeQuery(name), do_result)
+    sst.write_query(QueueQuery(name), do_action)
+
+
+# Apply monkey patch 2
+try:
+    import qpid.messaging.driver
+    qpid.messaging.driver.Engine.resolve_declare = resolve_declare_monkey
+    qpid.messaging.driver.Engine.resolve = resolve_monkey
+except ImportError:  # pragma: no cover
+    pass
+
+### End Monkey Patch 2 ###
+
+##### End Monkey Patching #####
+
+
+DEFAULT_PORT = 5672
+
+OBJECT_ALREADY_EXISTS_STRING = 'object already exists'
+
+# number of seconds to keep a queue around before deleting it.
+AUTO_DELETE_TIMEOUT = 3
+
+VERSION = (1, 0, 0)
+__version__ = '.'.join(map(str, VERSION))
+
+
+class QpidMessagingExceptionHandler(object):
+    """An exception handling decorator that silences some exceptions.
+
+    An exception handling class designed to silence specific exceptions
+    that qpid.messaging raises as part of normal operation. qpid.messaging
+    exceptions require string parsing, and are not machine consumable.
+    This is designed to be used as a decorator, and accepts a whitelist
+    string as an argument.
+
+    Usage:
+    @QpidMessagingExceptionHandler('whitelist string goes here')
+
+    """
+
+    def __init__(self, allowed_exception_string):
+        """Instantiate a QpidMessagingExceptionHandler object.
+
+        :param allowed_exception_string: a string that, if present in the
+            exception message, will be silenced.
+        :type allowed_exception_string: str
+
+        """
+        self.allowed_exception_string = allowed_exception_string
+
+    def __call__(self, original_func):
+        """The decorator method.
+
+        Method that wraps the actual function with exception silencing
+        functionality. Any exception that contains the string
+        self.allowed_exception_string in the message will be silenced.
+
+        :param original_func: function that is automatically passed in
+        when this object is used as a decorator.
+        :type original_func: function
+
+        :return: A function that decorates (wraps) the original function.
+        :rtype: func
+        """
+
+        def decorator(*args, **kwargs):
+            """A runtime-built function that will be returned which contains
+            a reference to the original function, and wraps a call to it in
+            a try/except block that can silence errors.
+            """
+            try:
+                return original_func(*args, **kwargs)
+            except Exception as error:
+                if self.allowed_exception_string not in error.message:
+                    raise
+
+        return decorator
+
+
+class QoS(object):
+    """A helper object for message prefetch and ACKing purposes.
+
+    This object is instantiated 1-for-1 with a :class:`Channel`.  QoS
+    allows prefetch_count to be set to the number of outstanding messages
+    the corresponding :class:`Channel` should be allowed to prefetch.
+    Setting prefetch_count to 0 disables prefetch limits, and the object
+    can hold an arbitrary number of messages.
+
+    Messages are added using :meth:`append`, which are held until they are
+    ACKed asynchronously through a call to :meth:`ack`.  Messages that are
+    received, but not ACKed will not be delivered by the broker to another
+    consumer until an ACK is received, or the session is closed. Messages
+    are referred to using delivery_tag integers, which are unique per
+    :class:`Channel`.  Delivery tags are managed outside of this object and
+    are passed in with a message to :meth:`append`.  Un-ACKed messages can
+    be looked up from QoS using :meth:`get` and can be rejected and
+    forgotten using :meth:`reject`.
+
+    """
+
+    def __init__(self, session, prefetch_count=1):
+        """Instantiate a QoS object.
+
+        :keyword prefetch_count: Initial prefetch count (defaults to 0,
+            which disables prefetch limits).
+        :type prefetch_count: int
+
+        """
+        if prefetch_count < 1:
+            raise Exception('prefetch_count must be >= 1')
+
+        self.session = session
+        self.prefetch_count = prefetch_count
+        self._not_yet_acked = OrderedDict()
+
+    def can_consume(self):
+        """Return True if the :class:`Channel` can consume more messages,
+        else False.
+
+        Used to ensure the client adheres to currently active prefetch
+        limits.
+
+        :returns: True, if this QoS object can accept more messages
+            without violating the prefetch_count.  If prefetch_count is 0,
+            can_consume will always return True.
+        :rtype: bool
+        """
+        return not self.prefetch_count or len(self._not_yet_acked) < self\
+            .prefetch_count
+
+    def can_consume_max_estimate(self):
+        """Return the remaining message capacity for the associated
+        :class:`Channel`.
+
+        Returns an estimated number of outstanding messages that a
+        :class:`Channel` can accept without exceeding prefetch_count.  If
+        prefetch_count is 0, then this method returns 1.
+
+        :returns: The number of estimated messages that can be fetched
+            without violating the prefetch_count.
+        :rtype: int
+        """
+        if self.prefetch_count:
+            return self.prefetch_count - len(self._not_yet_acked)
+        else:
+            return 1
+
+    def append(self, message, delivery_tag):
+        """Append message to the list of unacked messages.
+
+        Add a message, referenced by the integer delivery_tag, for ACKing,
+        rejecting, or getting later. Messages are saved into an
+        :class:`~kombu.utils.compat.OrderedDict` by delivery_tag.
+
+        :param message: A received message that has not yet been acked
+        :type message: qpid.messaging.Message
+        :param delivery_tag: An integer number to refer to this message by
+            upon receipt.
+        :type delivery_tag: int
+        """
+        self._not_yet_acked[delivery_tag] = message
+
+    def get(self, delivery_tag):
+        """
+        Get an un-ACKed message by delivery_tag.  If called with an invalid
+        delivery_tag a KeyError is raised.
+
+        :param delivery_tag: The delivery tag associated with the message
+            to be returned.
+        :type delivery_tag: int
+
+        :return: An un-ACKed message that is looked up by delivery_tag.
+        :rtype: qpid.messaging.Message
+        """
+        return self._not_yet_acked[delivery_tag]
+
+    def ack(self, delivery_tag):
+        """Acknowledge a message by delivery_tag.
+
+        Called asynchronously once the message has been handled and can be
+        forgotten by the broker.
+
+        :param delivery_tag: the delivery tag associated with the message
+            to be acknowledged.
+        :type delivery_tag: int
+        """
+        message = self._not_yet_acked.pop(delivery_tag)
+        self.session.acknowledge(message=message)
+
+    def reject(self, delivery_tag, requeue=False):
+        """Reject a message by delivery_tag.
+
+        Explicitly notify the broker that the :class:`Channel` associated
+        with this QoS object is rejecting the message that was previously
+        delivered.
+
+        If requeue is False, then the message is not requeued for delivery
+        to another consumer.  If requeue is True, then the message is
+        requeued for delivery to another consumer.
+
+        :param delivery_tag: The delivery tag associated with the message
+            to be rejected.
+        :type delivery_tag: int
+        :keyword requeue: If True, the broker will be notified to requeue
+            the message.  If False, the broker will be told to drop the
+            message entirely.  In both cases, the message will be removed
+            from this object.
+        :type requeue: bool
+        """
+        message = self._not_yet_acked.pop(delivery_tag)
+        QpidDisposition = qpid.messaging.Disposition
+        if requeue:
+            disposition = QpidDisposition(qpid.messaging.RELEASED)
+        else:
+            disposition = QpidDisposition(qpid.messaging.REJECTED)
+        self.session.acknowledge(message=message, disposition=disposition)
+
+
+class Channel(base.StdChannel):
+    """Supports broker configuration and messaging send and receive.
+
+    A Channel object is designed to have method-parity with a Channel as
+    defined in AMQP 0-10 and earlier, which allows for the following broker
+    actions:
+
+        - exchange declare and delete
+        - queue declare and delete
+        - queue bind and unbind operations
+        - queue length and purge operations
+        - sending/receiving/rejecting messages
+        - structuring, encoding, and decoding messages
+        - supports synchronous and asynchronous reads
+        - reading state about the exchange, queues, and bindings
+
+    Channels are designed to all share a single TCP connection with a
+    broker, but provide a level of isolated communication with the broker
+    while benefiting from a shared TCP connection.  The Channel is given
+    its :class:`Connection` object by the :class:`Transport` that
+    instantiates the Channel.
+
+    This Channel inherits from :class:`~kombu.transport.base.StdChannel`,
+    which makes this a 'native' Channel versus a 'virtual' Channel which
+    would inherit from :class:`kombu.transports.virtual`.
+
+    Messages sent using this Channel are assigned a delivery_tag. The
+    delivery_tag is generated for a message as they are prepared for
+    sending by :meth:`basic_publish`.  The delivery_tag is unique per
+    Channel instance using :meth:`~itertools.count`.  The delivery_tag has
+    no meaningful context in other objects, and is only maintained in the
+    memory of this object, and the underlying objects that provide support
+    (ie: :class:`QoS`).
+
+    Each Channel object instantiates exactly one :class:`QoS` object for
+    prefetch limiting, and asynchronous acking. The :class:`QoS` object is
+    lazily instantiated through a property method :meth:`qos`.  The
+    :class:`QoS` object is a supporting object that should not be accessed
+    directly except by the Channel itself.
+
+    Synchronous reads on a queue are done using a call to :meth:`basic_get`
+    which uses :meth:`_get` to perform the reading. These methods read
+    immediately and do not accept any form of timeout. :meth:`basic_get`
+    reads synchronously and ACKs messages before returning them, or acking
+    can be disable by the no_ack argument to :meth:`basic_get`.
+
+    Asynchronous reads on a queue are done by starting a consumer using
+    :meth:`basic_consume`.  Each call to :meth:`basic_consume` will cause a
+    thread to be started where a :class:`~qpid.messaging.endpoints.Receiver`
+    will perform a blocking read on the requested queue. Typically a more
+    efficient external I/O event notification system such as epoll or
+    kqueue would allow the kernel to monitor many file descriptors for
+    inbound data, but the :mod:`qpid.messaging` module does not allow an
+    external epoll or kqueue loop to be used. Consumers are given a
+    consumer tag by the caller of consumer_tag. Already started consumers
+    can be cancelled using by their consumer_tag using :meth:`basic_cancel`.
+
+    The Channel object handles thread creation of :class:`FDShimThread`
+    objects which provide asynchronous blocking reads.  FDShimThreads are
+    given a :class:`Queue.Queue` named delivery_queue to put messages into.
+    delivery_queue is provided by the creator of the Channel (typically a
+    :class:`Transport` object).  Cancellation of a consumer causes the
+    consuming class:`FDShimThread` to be notified it is no longer needed.
+
+    Asynchronous message acking is supported through :meth:`basic_ack`,
+    and is referenced by delivery_tag. The Channel object uses its
+    :class:`QoS` object to perform the message acking.
+
+    """
+
+    #: A class reference that will be instantiated using the qos property.
+    QoS = QoS
+
+    #: A class reference that identifies
+    # :class:`~kombu.transport.virtual.Message` as the message class type
+    Message = Message
+
+    #: Default body encoding.
+    #: NOTE: ``transport_options['body_encoding']`` will override this value.
+    body_encoding = 'base64'
+
+    #: Binary <-> ASCII codecs.
+    codecs = {'base64': Base64()}
+
+    #: counter used to generate delivery tags for this channel.
+    _delivery_tags = count(1)
+
+    def __init__(self, connection, transport):
+        """Instantiate a Channel object.
+
+        :param connection: A Connection object that this Channel can reference.
+            Currently only used to access callbacks.
+        :type connection: Connection
+        :param transport: The Transport this Channel is associated with.
+        :type transport: Transport
+        :param delivery_queue: A threadsafe queue that asynchronous
+            FDShimThread consumers should put arriving messages into.
+        :type delivery_queue: Queue.Queue
+        """
+        self.connection = connection
+        self.transport = transport
+        qpid_connection = connection.get_qpid_connection()
+        self._broker = qpidtoollibs.BrokerAgent(qpid_connection)
+        self.closed = False
+        self._tag_to_queue = {}
+        self._receivers = {}
+        self._qos = None
+
+    def _get(self, queue):
+        """Non-blocking, single-message read from a queue.
+
+        An internal method to perform a non-blocking, single-message read
+        from a queue by name. This method creates a
+        :class:`~qpid.messaging.endpoints.Receiver` to read from the queue
+        using the :class:`~qpid.messaging.endpoints.Session` referenced by
+        _qpid_session.  The receiver is closed before the method exits. If
+        a message is available, a :class:`qpid.messaging.Message`
+        object is returned.  If no message is available, a
+        :class:`qpid.messaging.exceptions.Empty` exception is raised.
+
+        This is an internal method.  External calls for get functionality
+        should be done using :meth:`basic_get`.
+
+        :param queue: The queue name to get the message from
+        :type queue: str
+
+        :return: The received message.
+        :rtype: :class:`qpid.messaging.Message`
+        """
+        rx = self.transport.session.receiver(queue)
+        try:
+            message = rx.fetch(timeout=0)
+        finally:
+            rx.close()
+        return message
+
+    def _put(self, routing_key, message, exchange=None, **kwargs):
+        """Synchronous send of a single message onto a queue or exchange.
+
+        An internal method which synchronously sends a single message onto
+        a given queue or exchange.  If exchange is not specified,
+        the message is sent directly to a queue specified by routing_key.
+        If no queue is found by the name of routing_key while exchange is
+        not specified an exception is raised.  If an exchange is specified,
+        then the message is delivered onto the requested
+        exchange using routing_key. Message sending is synchronous using
+        sync=True because large messages in kombu funtests were not being
+        fully sent before the receiver closed.
+
+        This method creates a :class:`qpid.messaging.endpoints.Sender` to
+        send the message to the queue using the
+        :class:`qpid.messaging.endpoints.Session` referenced by
+        _qpid_session.  The sender is closed before the method exits.
+
+        External calls for put functionality should be done using
+        :meth:`basic_publish`.
+
+        :param routing_key: If exchange is None, treated as the queue name
+            to send the message to. If exchange is not None, treated as the
+            routing_key to use as the message is submitted onto the exchange.
+        :type routing_key: str
+        :param message: The message to be sent as prepared by
+            :meth:`basic_publish`.
+        :type message: dict
+        :keyword exchange: keyword parameter of the exchange this message
+            should be sent on. If no exchange is specified, the message is
+            sent directly to a queue specified by routing_key.
+        :type exchange: str
+        """
+        if not exchange:
+            address = '%s; {assert: always, node: {type: queue}}' % \
+                      routing_key
+            msg_subject = None
+        else:
+            address = '%s/%s; {assert: always, node: {type: topic}}' % (
+                exchange, routing_key)
+            msg_subject = str(routing_key)
+        sender = self.transport.session.sender(address)
+        qpid_message = qpid.messaging.Message(content=message,
+                                              subject=msg_subject)
+        try:
+            sender.send(qpid_message, sync=True)
+        finally:
+            sender.close()
+
+    def _purge(self, queue):
+        """Purge all undelivered messages from a queue specified by name.
+
+        An internal method to purge all undelivered messages from a queue
+        specified by name.  The queue message depth is first checked,
+        and then the broker is asked to purge that number of messages.  The
+        integer number of messages requested to be purged is returned. The
+        actual number of messages purged may be different than the
+        requested number of messages to purge (see below).
+
+        Sometimes delivered messages are asked to be purged, but are not.
+        This case fails silently, which is the correct behavior when a
+        message that has been delivered to a different consumer, who has
+        not acked the message, and still has an active session with the
+        broker. Messages in that case are not safe for purging and will be
+        retained by the broker.  The client is unable to change this
+        delivery behavior.
+
+        This is an internal method.  External calls for purge functionality
+        should be done using :meth:`queue_purge`.
+
+        :param queue: the name of the queue to be purged
+        :type queue: str
+
+        :return: The number of messages requested to be purged.
+        :rtype: int
+        """
+        queue_to_purge = self._broker.getQueue(queue)
+        message_count = queue_to_purge.values['msgDepth']
+        if message_count > 0:
+            queue_to_purge.purge(message_count)
+        return message_count
+
+    def _size(self, queue):
+        """Get the number of messages in a queue specified by name.
+
+        An internal method to return the number of messages in a queue
+        specified by name.  It returns an integer count of the number
+        of messages currently in the queue.
+
+        :param queue: The name of the queue to be inspected for the number
+            of messages
+        :type queue: str
+
+        :return the number of messages in the queue specified by name.
+        :rtype: int
+        """
+        queue_to_check = self._broker.getQueue(queue)
+        message_depth = queue_to_check.values['msgDepth']
+        return message_depth
+
+    def _delete(self, queue, *args, **kwargs):
+        """Delete a queue and all messages on that queue.
+
+        An internal method to delete a queue specified by name and all the
+        messages on it. First, all messages are purged from a queue using a
+        call to :meth:`_purge`.  Second, the broker is asked to delete the
+        queue.
+
+        This is an internal method.  External calls for queue delete
+        functionality should be done using :meth:`queue_delete`.
+
+        :param queue: The name of the queue to be deleted.
+        :type queue: str
+        """
+        self._purge(queue)
+        self._broker.delQueue(queue)
+
+    def _has_queue(self, queue, **kwargs):
+        """Determine if the broker has a queue specified by name.
+
+        :param queue: The queue name to check if the queue exists.
+        :type queue: str
+
+        :return: True if a queue exists on the broker, and false
+            otherwise.
+        :rtype: bool
+        """
+        if self._broker.getQueue(queue):
+            return True
+        else:
+            return False
+
+    def queue_declare(self, queue, passive=False, durable=False,
+                      exclusive=False, auto_delete=True, nowait=False,
+                      arguments=None):
+        """Create a new queue specified by name.
+
+        If the queue already exists, no change is made to the queue,
+        and the return value returns information about the existing queue.
+
+        The queue name is required and specified as the first argument.
+
+        If passive is True, the server will not create the queue.  The
+        client can use this to check whether a queue exists without
+        modifying the server state.  Default is False.
+
+        If durable is True, the queue will be durable.  Durable queues
+        remain active when a server restarts. Non-durable queues (
+        transient queues) are purged if/when a server restarts.  Note that
+        durable queues do not necessarily hold persistent messages,
+        although it does not make sense to send persistent messages to a
+        transient queue.  Default is False.
+
+        If exclusive is True, the queue will be exclusive. Exclusive queues
+        may only be consumed by the current connection. Setting the
+        'exclusive' flag always implies 'auto-delete'.  Default is False.
+
+        If auto_delete is True,  the queue is deleted when all consumers
+        have finished using it. The last consumer can be cancelled either
+        explicitly or because its channel is closed. If there was no
+        consumer ever on the queue, it won't be deleted.  Default is True.
+
+        The nowait parameter is unused.  It was part of the 0-9-1 protocol,
+        but this AMQP client implements 0-10 which removed the nowait option.
+
+        The arguments parameter is a set of arguments for the declaration of
+        the queue.  Arguments are passed as a dict or None. This field is
+        ignored if passive is True.  Default is None.
+
+        This method returns a :class:`~collections.namedtuple` with the name
+        'queue_declare_ok_t' and the queue name as 'queue', message count
+        on the queue as 'message_count', and the number of active consumers
+        as 'consumer_count'.  The named tuple values are ordered as queue,
+        message_count, and consumer_count respectively.
+
+        :param queue: The name of the queue to be created.
+        :type queue: str
+        :param passive: If True, the sever will not create the queue.
+        :type passive: bool
+        :param durable: If True, the queue will be durable.
+        :type durable: bool
+        :param exclusive: If True, the queue will be exclusive.
+        :type exclusive: bool
+        :param auto_delete: If True, the queue is deleted when all
+            consumers have finished using it.
+        :type auto_delete: bool
+        :param nowait: This parameter is unused since the 0-10
+            specification does not include it.
+        :type nowait: bool
+        :param arguments: A set of arguments for the declaration of the
+            queue.
+        :type arguments: dict or None
+
+        :return: A named tuple representing the declared queue as a named
+            tuple.  The tuple values are ordered as queue, message count,
+            and the active consumer count.
+        :rtype: :class:`~collections.namedtuple`
+
+        """
+        options = {'passive': passive,
+                   'durable': durable,
+                   'exclusive': exclusive,
+                   'auto-delete': auto_delete,
+                   'arguments': arguments}
+        options['qpid.auto_delete_timeout'] = AUTO_DELETE_TIMEOUT
+        if queue.startswith('celeryev') or queue.endswith('pidbox'):
+            options['qpid.policy_type'] = 'ring'
+        try:
+            self._broker.addQueue(queue, options=options)
+        except Exception as err:
+            if OBJECT_ALREADY_EXISTS_STRING not in err.message:
+                raise err
+        queue_to_check = self._broker.getQueue(queue)
+        message_count = queue_to_check.values['msgDepth']
+        consumer_count = queue_to_check.values['consumerCount']
+        return amqp.protocol.queue_declare_ok_t(queue, message_count,
+                                                consumer_count)
+
+    def queue_delete(self, queue, if_unused=False, if_empty=False, **kwargs):
+        """Delete a queue by name.
+
+        Delete a queue specified by name.  Using the if_unused keyword
+        argument, the delete can only occur if there are 0 consumers bound
+        to it.  Using the if_empty keyword argument, the delete can only
+        occur if there are 0 messages in the queue.
+
+        :param queue: The name of the queue to be deleted.
+        :type queue: str
+        :keyword if_unused: If True, delete only if the queue has 0
+            consumers.  If False, delete a queue even with consumers bound
+            to it.
+        :type if_unused: bool
+        :keyword if_empty: If True, only delete the queue if it is empty.  If
+            False, delete the queue if it is empty or not.
+        :type if_empty: bool
+        """
+        if self._has_queue(queue):
+            if if_empty and self._size(queue):
+                return
+            queue_obj = self._broker.getQueue(queue)
+            consumer_count = queue_obj.getAttributes()['consumerCount']
+            if if_unused and consumer_count > 0:
+                return
+            self._delete(queue)
+
+    @QpidMessagingExceptionHandler(OBJECT_ALREADY_EXISTS_STRING)
+    def exchange_declare(self, exchange='', type='direct', durable=False,
+                         **kwargs):
+        """Create a new exchange.
+
+        Create an exchange of a specific type, and optionally have the
+        exchange be durable.  If an exchange of the requested name already
+        exists, no action is taken and no exceptions are raised.  Durable
+        exchanges will survive a broker restart, non-durable exchanges will
+        not.
+
+        Exchanges provide behaviors based on their type.  The expected
+        behaviors are those defined in the AMQP 0-10 and prior
+        specifications including 'direct', 'topic', and 'fanout'
+        functionality.
+
+        :keyword type: The exchange type. Valid values include 'direct',
+        'topic', and 'fanout'.
+        :type type: str
+        :keyword exchange: The name of the exchange to be created.  If no
+        exchange is specified, then a blank string will be used as the name.
+        :type exchange: str
+        :keyword durable: True if the exchange should be durable, or False
+        otherwise.
+        :type durable: bool
+        """
+        options = {'durable': durable}
+        self._broker.addExchange(type, exchange, options)
+
+    def exchange_delete(self, exchange_name, **kwargs):
+        """Delete an exchange specified by name
+
+        :param exchange_name: The name of the exchange to be deleted.
+        :type exchange_name: str
+        """
+        self._broker.delExchange(exchange_name)
+
+    def queue_bind(self, queue, exchange, routing_key, **kwargs):
+        """Bind a queue to an exchange with a bind key.
+
+        Bind a queue specified by name, to an exchange specified by name,
+        with a specific bind key.  The queue and exchange must already
+        exist on the broker for the bind to complete successfully. Queues
+        may be bound to exchanges multiple times with different keys.
+
+        :param queue: The name of the queue to be bound.
+        :type queue: str
+        :param exchange: The name of the exchange that the queue should be
+            bound to.
+        :type exchange: str
+        :param routing_key: The bind key that the specified queue should
+            bind to the specified exchange with.
+        :type routing_key: str
+        """
+        self._broker.bind(exchange, queue, routing_key)
+
+    def queue_unbind(self, queue, exchange, routing_key, **kwargs):
+        """Unbind a queue from an exchange with a given bind key.
+
+        Unbind a queue specified by name, from an exchange specified by
+        name, that is already bound with a bind key.  The queue and
+        exchange must already exist on the broker, and bound with the bind
+        key for the operation to complete successfully.  Queues may be
+        bound to exchanges multiple times with different keys, thus the
+        bind key is a required field to unbind in an explicit way.
+
+        :param queue: The name of the queue to be unbound.
+        :type queue: str
+        :param exchange: The name of the exchange that the queue should be
+            unbound from.
+        :type exchange: str
+        :param routing_key: The existing bind key between the specified
+            queue and a specified exchange that should be unbound.
+        :type routing_key: str
+        """
+        self._broker.unbind(exchange, queue, routing_key)
+
+    def queue_purge(self, queue, **kwargs):
+        """Remove all undelivered messages from queue.
+
+        Purge all undelivered messages from a queue specified by name.  The
+        queue message depth is first checked, and then the broker is asked
+        to purge that number of messages.  The integer number of messages
+        requested to be purged is returned. The actual number of messages
+        purged may be different than the requested number of messages to
+        purge.
+
+        Sometimes delivered messages are asked to be purged, but are not.
+        This case fails silently, which is the correct behavior when a
+        message that has been delivered to a different consumer, who has
+        not acked the message, and still has an active session with the
+        broker. Messages in that case are not safe for purging and will be
+        retained by the broker.  The client is unable to change this
+        delivery behavior.
+
+        Internally, this method relies on :meth:`_purge`.
+
+        :param queue: The name of the queue which should have all messages
+            removed.
+        :type queue: str
+
+        :return: The number of messages requested to be purged.
+        :rtype: int
+        """
+        return self._purge(queue)
+
+    def basic_get(self, queue, no_ack=False, **kwargs):
+        """Non-blocking single message get and ack from a queue by name.
+
+        Internally this method uses :meth:`_get` to fetch the message.  If
+        an :class:`~qpid.messaging.exceptions.Empty` exception is raised by
+        :meth:`_get`, this method silences it and returns None.  If
+        :meth:`_get` does return a message, that message is acked according
+        to the value of no_ack and returned.  If no_ack is True,
+        the message is not acked, and if no_ack is False, By default,
+        the message is acked.  This method never adds fetched Messages to
+        the internal QoS object for asynchronous acking.
+
+        This method converts the object type of the method as it passes
+        through.  Fetching from the broker, :meth:`_get` returns a
+        :class:`qpid.messaging.Message`, but this method takes the payload
+        of the :class:`qpid.messaging.Message` and instantiates a
+        :class:`~kombu.transport.virtual.Message` object with the payload
+        based on the class setting of self.Message.
+
+        :param queue: The queue name to fetch a message from.
+        :type queue: str
+        :keyword no_ack: If True, a message fetched will not be acked. If
+            False, a message fetched will be acked.
+        :type noack: bool
+
+        :return: The received message.
+        :rtype: :class:`~kombu.transport.virtual.Message`
+        """
+        try:
+            qpid_message = self._get(queue)
+            raw_message = qpid_message.content
+            message = self.Message(self, raw_message)
+            if not no_ack:
+                self.transport.session.acknowledge(message=qpid_message)
+            return message
+        except Empty:
+            pass
+
+    def basic_ack(self, delivery_tag):
+        """Acknowledge a message by delivery_tag.
+
+        Acknowledges a message referenced by delivery_tag.  Messages can
+        only be ack'ed using :meth:`basic_ack` if they were acquired using
+        :meth:`basic_consume`.  This is the acking portion of the
+        asynchronous read behavior.
+
+        Internally, this method uses the :class:`QoS` object, which stores
+        messages and is responsible for the ACKing.
+
+        :param delivery_tag: The delivery tag associated with the message
+            to be acknowledged.
+        :type delivery_tag: int
+        """
+        self.qos.ack(delivery_tag)
+
+    def basic_reject(self, delivery_tag, requeue=False):
+        """Reject a message by delivery_tag.
+
+        Rejects a message that has been received by the Channel, but not
+        yet acknowledged.  Messages are referenced by their delivery_tag.
+
+        If requeue is False, the rejected message will be dropped by the
+        broker and not delivered to any other consumers.  If requeue is
+        True, then the rejected message will be requeued for delivery to
+        another consumer, potentially to the same consumer who rejected the
+        message previously.
+
+        :param delivery_tag: The delivery tag associated with the message
+            to be rejected.
+        :type delivery_tag: int
+        :keyword requeue: If False, the rejected message will be dropped by
+            the broker and not delivered to any other consumers.  If True,
+            then the rejected message will be requeued for delivery to
+            another consumer, potentially to the same consumer who rejected
+            the message previously.
+        :type requeue: bool
+
+        """
+        self.qos.reject(delivery_tag, requeue=requeue)
+
+    def basic_consume(self, queue, no_ack, callback, consumer_tag, **kwargs):
+        """Start an asynchronous consumer that reads from a queue.
+
+        This method starts a consumer that reads messages from a queue
+        specified by name until stopped by a call to :meth:`basic_cancel`.
+        Once a message is read, a call to the callback will occur with the
+        message as the single argument.  The message passed to the callback
+        is of type self.Message.  Each consumer is referenced by a
+        consumer_tag, which is provided by the caller of this method.
+
+        Consuming is done using a thread of type :class:`FDShimThread` that
+        is spawned when this method is called.  The child thread is marked as
+        a daemon, indicating that if all non-daemon threads exit, the child
+        consumer thread will also exit.  The child consumer thread performs
+        an efficient blocking read, which wakes up regularly to see if it
+        should exit.
+
+        The child consumer thread does not call the callback directly.
+        Instead, the child thread is given a threadsafe :class:`Queue.Queue`
+        object which it should deliver messages into.  This single queue
+        aggregates all consumer messages, and can be read through a call to
+        :meth:`~Transport.drain_events` on the Transport object associated
+        with this Channel object.  This method sets up the callback onto the
+        self.connection object in a dict keyed by queue name.
+        :meth:`~Transport.drain_events` is responsible for calling that
+        callback upon message receipt.
+
+        Depending on the value of the no_ack parameter, the message that is
+        received can be saved for asynchronous acking later after the
+        message has been handled by the caller of
+        :meth:`~Transport.drain_events`. Messages can be acked after being
+        received through a call to :meth:`basic_ack`. If no_ack is True,
+        then messages are not saved for acking later. If no_ack is False,
+        then messages are saved for acking later. Internally the :class:`QoS`
+        object is used to store messages for acking later.
+
+        :meth:`basic_consume` transforms the message object type prior to
+        calling the callback.  Initially the message comes in as a
+        :class:`qpid.messaging.Message`.  This method unpacks the payload
+        of the :class:`qpid.messaging.Message` and creates a new object of
+        type self.Message.
+
+        This method wraps the user delivered callback in a runtime-built
+        function which provides the type transformation from
+        :class:`qpid.messaging.Message` to
+        :class:`~kombu.transport.virtual.Message`, and adds the message to
+        the associated :class:`QoS` object for asynchronous acking
+        if necessary.
+
+        :param queue: The name of the queue to consume messages from
+        :type queue: str
+        :param no_ack: If True, then messages will not be saved for
+            acking later.  If False, then messages will be saved for acking
+            later.
+        :type no_ack: bool
+        :param callback: a callable that will be called when messages
+            arrive on the queue.
+        :type callback: a callable object
+        :param consumer_tag: a tag to reference the created consumer by.
+            This consumer_tag is needed to cancel the consumer.
+        :type consumer_tag: an immutable object
+        """
+        self._tag_to_queue[consumer_tag] = queue
+
+        def _callback(qpid_message):
+            raw_message = qpid_message.content
+            message = self.Message(self, raw_message)
+            if not no_ack:
+                delivery_tag = message.delivery_tag
+                self.qos.append(qpid_message, delivery_tag)
+            return callback(message)
+
+        self.connection._callbacks[queue] = _callback
+        new_receiver = self.transport.session.receiver(queue)
+        new_receiver.capacity = self.qos.prefetch_count
+        self._receivers[consumer_tag] = new_receiver
+
+    def basic_cancel(self, consumer_tag):
+        """Cancel consumer by consumer tag.
+
+        Request the consumer stops reading messages from its queue. The
+        consumer is a child thread, and it is told to stop by a call to
+        the :meth:`kill` method on the thread object.  Killing does not
+        occur immediately, but will occur once the child completes its
+        blocking read and checks if it should die or not.  The thread is
+        not waited on to die because in practice there can be many
+        consumers, and they are killed through a series of serial calls to
+        this method, which would take a long time.
+
+        This method also cleans up all lingering references of the consumer.
+
+        :param consumer_tag: The tag which refers to the consumer to be
+            cancelled.  Originally specified when the consumer was created
+            as a parameter to :meth:`basic_consume`.
+        :type consumer_tag: an immutable object
+        """
+        if consumer_tag in self._receivers:
+            self._receivers.pop(consumer_tag)
+            queue = self._tag_to_queue.pop(consumer_tag, None)
+            self.connection._callbacks.pop(queue, None)
+
+    def close(self):
+        """Close Channel and all associated messages.
+
+        This cancels all consumers by calling :meth:`basic_cancel` for each
+        known consumer_tag.  It also closes the self._qpid_session and
+        self._broker sessions.  Closing the sessions implicitly causes all
+        outstanding, unacked messages to be considered undelivered by the
+        broker.
+        """
+        if not self.closed:
+            self.closed = True
+            for consumer_tag in self._receivers.keys():
+                self.basic_cancel(consumer_tag)
+            if self.connection is not None:
+                self.connection.close_channel(self)
+            self._broker.close()
+
+    @property
+    def qos(self):
+        """:class:`QoS` manager for this channel.
+
+        Lazily instantiates an object of type :class:`QoS` upon access to
+        the self.qos attribute.
+
+        :return: An already existing, or newly created QoS object
+        :rtype: :class:`QoS`
+        """
+        if self._qos is None:
+            self._qos = self.QoS(self.transport.session)
+        return self._qos
+
+    def basic_qos(self, prefetch_count, *args):
+        """Change :class:`QoS` settings for this Channel.
+
+        Set the number of unacknowledged messages this Channel can fetch and
+        hold.  For instance prefetch_count=3 will allow a maximum of 3
+        unacked messages to be received from the broker.
+
+        :param prefetch_count: The number of outstanding, unacked messages
+            this Channel is allowed to have.
+        :type prefetch_count: int
+        """
+        self.qos.prefetch_count = 1
+
+    def prepare_message(self, body, priority=None, content_type=None,
+                        content_encoding=None, headers=None, properties=None):
+        """Prepare message data for sending.
+
+        This message is typically called by
+        :meth:`kombu.messaging.Producer._publish` as a preparation step in
+        message publication.
+
+        :param body: The body of the message
+        :type body: str
+        :keyword priority: A number between 0 and 9 that sets the priority of
+            the message.
+        :type priority: int
+        :keyword content_type: The content_type the message body should be
+            treated as.  If this is unset, the
+            :class:`qpid.messaging.endpoints.Sender` object tries to
+            autodetect the content_type from the body.
+        :type content_type: str
+        :keyword content_encoding: The content_encoding the message body is
+            encoded as.
+        :type content_encoding: str
+        :keyword headers: Additional Message headers that should be set.
+            Passed in as a key-value pair.
+        :type headers: dict
+        :keyword properties: Message properties to be set on the message.
+        :type properties: dict
+
+        :return: Returns a dict object that encapsulates message
+            attributes.  See parameters for more details on attributes that
+            can be set.
+        :rtype: dict
+        """
+        properties = properties or {}
+        info = properties.setdefault('delivery_info', {})
+        info['priority'] = priority or 0
+
+        return {'body': body,
+                'content-encoding': content_encoding,
+                'content-type': content_type,
+                'headers': headers or {},
+                'properties': properties or {}}
+
+    def basic_publish(self, message, exchange, routing_key, **kwargs):
+        """Publish message onto an exchange using a routing key.
+
+        Publish a message onto an exchange specified by name using a
+        routing key specified by routing_key.  Prepares the message in the
+        following ways before sending:
+
+        - encodes the body using :meth:`encode_body`
+        - wraps the body as a buffer object, so that
+            :class:`qpid.messaging.endpoints.Sender` uses a content type
+            that can support arbitrarily large messages.
+        - assigns a delivery_tag generated through self._delivery_tags
+        - sets the exchange and routing_key info as delivery_info
+
+        Internally uses :meth:`_put` to send the message synchronously.  This
+        message is typically called by
+        :class:`kombu.messaging.Producer._publish` as the final step in
+        message publication.
+
+        :param message: A dict containing key value pairs with the message
+            data.  A valid message dict can be generated using the
+            :meth:`prepare_message` method.
+        :type message: dict
+        :param exchange: The name of the exchange to submit this message
+            onto.
+        :type exchange: str
+        :param routing_key: The routing key to be used as the message is
+            submitted onto the exchange.
+        :type routing_key: str
+        """
+        message['body'], body_encoding = self.encode_body(
+            message['body'], self.body_encoding,
+        )
+        message['body'] = buffer(message['body'])
+        props = message['properties']
+        props.update(
+            body_encoding=body_encoding,
+            delivery_tag=next(self._delivery_tags),
+        )
+        props['delivery_info'].update(
+            exchange=exchange,
+            routing_key=routing_key,
+        )
+        self._put(routing_key, message, exchange, **kwargs)
+
+    def encode_body(self, body, encoding=None):
+        """Encode a body using an optionally specified encoding.
+
+        The encoding can be specified by name, and is looked up in
+        self.codecs.  self.codecs uses strings as its keys which specify
+        the name of the encoding, and then the value is an instantiated
+        object that can provide encoding/decoding of that type through
+        encode and decode methods.
+
+        :param body: The body to be encoded.
+        :type body: str
+        :keyword encoding: The encoding type to be used.  Must be a supported
+            codec listed in self.codecs.
+        :type encoding: str
+
+        :return: If encoding is specified, return a tuple with the first
+            position being the encoded body, and the second position the
+            encoding used.  If encoding is not specified, the body is passed
+            through unchanged.
+        :rtype: tuple
+        """
+        if encoding:
+            return self.codecs.get(encoding).encode(body), encoding
+        return body, encoding
+
+    def decode_body(self, body, encoding=None):
+        """Decode a body using an optionally specified encoding.
+
+        The encoding can be specified by name, and is looked up in
+        self.codecs.  self.codecs uses strings as its keys which specify
+        the name of the encoding, and then the value is an instantiated
+        object that can provide encoding/decoding of that type through
+        encode and decode methods.
+
+        :param body: The body to be encoded.
+        :type body: str
+        :keyword encoding: The encoding type to be used.  Must be a supported
+            codec listed in self.codecs.
+        :type encoding: str
+
+        :return: If encoding is specified, the decoded body is returned.
+            If encoding is not specified, the body is returned unchanged.
+        :rtype: str
+        """
+        if encoding:
+            return self.codecs.get(encoding).decode(body)
+        return body
+
+    def typeof(self, exchange, default='direct'):
+        """Get the exchange type.
+
+        Lookup and return the exchange type for an exchange specified by
+        name.  Exchange types are expected to be 'direct', 'topic',
+        and 'fanout', which correspond with exchange functionality as
+        specified in AMQP 0-10 and earlier.  If the exchange cannot be
+        found, the default exchange type is returned.
+
+        :param exchange: The exchange to have its type lookup up.
+        :type exchange: str
+        :keyword default: The type of exchange to assume if the exchange does
+            not exist.
+        :type default: str
+
+        :return: The exchange type either 'direct', 'topic', or 'fanout'.
+        :rtype: str
+        """
+        qpid_exchange = self._broker.getExchange(exchange)
+        if qpid_exchange:
+            qpid_exchange_attributes = qpid_exchange.getAttributes()
+            return qpid_exchange_attributes["type"]
+        else:
+            return default
+
+
+class TransportReceiver(threading.Thread):
+    """Monitor and handle messages from all consumer threads.
+
+    The FDShim object monitors incoming messages from all consumers
+    through a blocking read on the threadsafe queue that consumers
+    deliver messages into, delivery_queue.  Once a message is received
+    by FDShim, an externally monitorable file descriptor is set that data
+    is ready for the transport, and the message is put into a separate
+    threadsafe queue referenced at self.queue_from_fdshim.
+
+    The FDShim object provides a read file descriptor named self.r which
+    can be monitored by an external epoll-like event I/O notification
+    system.  An external epoll loop would monitor self.r when it wants to
+    be notified efficiently that the Transport associated with this FDShim
+    has data available for reading.  The client library qpid.messaging does
+    not make available read file descriptors for external monitoring,
+    and so FDShim provides this functionality by creating os.pipe() based
+    file descriptors that it writes into causing external epoll loops
+    to efficiently "wake up" at the correct time.
+
+    FDShim objects are designed to be used by a :class:`Transport`, and
+    should not be used by external objects directly.  Each :class:`Transport`
+    creates exactly one FDShim object to monitor and handle messages from all
+    consumers associated with all :class:`Channels` associated with the
+    :class:`Transport`.  The thread entry point is :meth:`monitor_consumers`.
+    The :class:`Transport` daemonizes the thread before calling :meth:`start`
+    ensuring an FDShim will never keep the Python process alive if all
+    non-daemon threads have exited.
+
+    """
+
+    def __init__(self, session, delivery_queue, w_fd):
+        """Instantiate a FDShim object.
+
+        :param queue_from_fdshim: The queue that that messages which are ready
+            for reading are put into so that the :class:`Transport` can drain
+            them with a call to :meth:`Transport.drain_events`
+        :type queue_from_fdshim: Queue.Queue
+        :param delivery_queue: The queue that FDShim performs a blocking
+            read on to receive messages form all consumers associated with all
+            :class:`Channel` objects associated with the :class:`Transport`
+            that created FDShim.
+        :type delivery_queue: Queue.Queue
+
+        """
+        self._session = session
+        self._delivery_queue = delivery_queue
+        self._w_fd = w_fd
+        super(TransportReceiver, self).__init__()
+
+    def run(self):
+        while True:
+            try:
+                self.monitor_receivers()
+            except Exception as e:
+                logger.error(e)
+            time.sleep(10)
+
+    def monitor_receivers(self):
+        """The thread entry point.
+
+        Do a blocking read call similar to what qpid.messaging does, and when
+        something is received, set the pipe as being readable, and then put
+        the message into the queue_from_fdshim object.
+
+        Setting the pipe as being readable is done by writing a single '0'
+        character into the pipe so that anything monitoring it will receive
+        the ready for reading signal.
+        """
+        while True:
+            receiver = self._session.next_receiver()
+            message = receiver.fetch()
+            queue = receiver.source
+            response_bundle = (queue, message)
+            self._delivery_queue.put(response_bundle)
+            os.write(self._w_fd, '0')
+
+
+class Connection(object):
+    """Encapsulate a connection object for the :class:`Transport`.
+
+    A Connection object is created by a :class:`Transport` during a call to
+    :meth:`Transport.establish_connection`.  The :class:`Transport` passes in
+    connection options as keywords that should be used for any connections
+    created. Each :class:`Transport` creates exactly one Connection.
+
+    Objects that use connections to the broker such as
+    :class:`Channel`, :class:`QoS`, and :class:`FDShimThread` objects need to
+    have independent connections generated.  Any part of this codebase can
+    get a valid connection to the broker with parameters saved in this object
+    by calling the bound :meth:`get_qpid_connection` method.
+
+    The Connection object is also responsible for maintaining the
+    dictionary of references to callbacks that should be called when
+    messages are received.  These callbacks are saved in _callbacks,
+    and keyed on the queue name associated with the received message.  The
+    _callbacks are setup in :meth:`Channel.basic_consume`, removed in
+    :meth:`Channel.basic_cancel`, and called in
+    :meth:`Transport.drain_events`.
+
+    The following keys are expected to be passed in as keyword arguments
+    at a minimum:
+
+    All keyword arguments are collected into the connection_options dict
+    and passed directly through to qpid.messaging.
+    """
+
+    # A class reference to the :class:`Channel` object
+    Channel = Channel
+
+    def __init__(self, **connection_options):
+        """Instantiate a Connection object.
+
+        The following parameters are expected:
+
+        * host: The host that connections should connect to.
+        * port: The port that connection should connect to.
+        * username: The username that connections should connect with.
+        * password: The password that connections should connect with.
+        * transport: The transport type that connections should use.  Either
+              'tcp', or 'ssl' are expected as values.
+        * timeout: the timeout to use when a Connection connects to the broker.
+        * sasl_mechanisms: The sasl authentication mechanism type to use. refer
+              to SASL documentation for an explanation of valid values.
+
+        Creates a :class:`qpid.messaging.endpoints.Connection` object with
+        the saved parameters, and stores it as _qpid_conn.
+
+        """
+        self.connection_options = connection_options
+        self.channels = []
+        self._callbacks = {}
+        self._qpid_conn = qpid.messaging.Connection.establish(**self.connection_options)
+
+    def get_qpid_connection(self):
+        """Return the existing connection (singleton).
+
+        :return: The existing qpid.messaging connection
+        :rtype: :class:`qpid.messaging.endpoints.Connection`
+        """
+        return self._qpid_conn
+
+    def close_channel(self, channel):
+        """Close a Channel.
+
+        Close a channel specified by a reference to the :class:`Channel`
+        object.
+
+        :param channel: Channel that should be closed.
+        :type channel: Channel
+        """
+        try:
+            self.channels.remove(channel)
+        except ValueError:
+            pass
+        finally:
+            channel.connection = None
+
+
+class Transport(base.Transport):
+    """Kombu native transport for a Qpid broker.
+
+    Provide a native transport for Kombu that allows consumers and
+    producers to read and write messages to/from a broker.  This Transport
+    is capable of supporting both synchronous and asynchronous reading.
+    All writes are synchronous through the :class:`Channel` objects that
+    support this Transport.
+
+    Synchronous reads are done using a call to :meth:`drain_events`,
+    which synchronously reads events, and then handles them through
+    calls to the callback handlers maintained on the :class:`Connection`
+    object.
+
+    Asynchronous reads are done by monitoring the file descriptor
+    self.fd_shim.r which will be sent the signal indicating it is ready for
+    reading when messages are ready to be read.  When this file
+    descriptor is ready for reading, the monitor should call
+    :meth:`on_readable` as the callback, with the message as the
+    parameter, when the external loop is ready to read and handle
+    messages that are associated with this Transport.
+
+    The Transport also provides methods to establish and close a connection
+    to the broker.  This Transport establishes a factory-like pattern that
+    allows for lazy creation of Connections as needed.
+
+    The Transport can create :class:`Channel` objects to communicate with the
+    broker with using the :meth:`create_channel` method.
+
+    """
+
+    # Reference to the class that should be used as the Connection object
+    Connection = Connection
+
+    # The default port
+    default_port = DEFAULT_PORT
+
+    # This Transport does not support polling as its primary fetching model.
+    polling_interval = None
+
+    # This Transport does support an asynchronous event model.
+    supports_ev = True
+
+    # The driver type and name for identification purposes.
+    driver_type = 'qpid'
+    driver_name = 'qpid'
+
+    def __init__(self, client, **kwargs):
+        """Instantiate a Transport object.
+
+        :param client: A reference to the creator of the Transport.
+        :type client: kombu.connection.Connection
+
+        """
+        self.delivery_queue = Queue.Queue()
+        self.r_fd, self.w_fd = os.pipe()
+        super(Transport, self).__init__(client, **kwargs)
+
+    def register_with_event_loop(self, connection, loop):
+        """Register a file descriptor and callback with the loop.
+
+        Register the callback self.on_readable to be called when an
+        external epoll loop sees that the file descriptor registered is
+        ready for reading.  The file descriptor is created and updated by
+        :class:`FDShim`, which is created by the Transport at instantiation
+        time.
+
+        When supports_ev = True, Celery expects to call this method to give
+        the Transport an opportunity to register a read file descriptor for
+        external monitoring by celery using an Event I/O notification
+        mechanism such as epoll.  A callback is also registered that is to
+        be called once the external epoll loop is ready to handle the epoll
+        event associated with messages that are ready to be handled for
+        this Transport.
+
+        The registration call is made exactly once per Transport after the
+        Transport is finished instantiating.
+
+        :param connection: A reference to the connection associated with
+            this Transport.
+        :type connection: Connection
+        :param loop: A reference to the external loop.
+        :type loop: kombu.async.hub.Hub
+        """
+        loop.add_reader(self.r_fd, self.on_readable, connection, loop)
+
+    def establish_connection(self):
+        """Establish a Connection object.
+
+        Determines the correct options to use when creating any connections
+        needed by this Transport, and create a :class:`Connection` object
+        which saves those values for connections generated as they are
+        needed.  The options are a mixture of what is passed in through the
+        creator of the Transport, and the defaults provided by
+        :meth:`default_connection_params`.  Options cover broker network
+        settings, timeout behaviors, authentication, and identity
+        verification settings.
+
+        :return: The created :class:`Connection` object is returned.
+        :rtype: :class:`Connection`
+        """
+        conninfo = self.client
+        for name, default_value in items(self.default_connection_params):
+            if not getattr(conninfo, name, None):
+                setattr(conninfo, name, default_value)
+        if conninfo.hostname == 'localhost':
+            conninfo.hostname = '127.0.0.1'
+        if conninfo.ssl:
+            conninfo.qpid_transport = 'ssl'
+            conninfo.transport_options['ssl_keyfile'] = conninfo.ssl[
+                'keyfile']
+            conninfo.transport_options['ssl_certfile'] = conninfo.ssl[
+                'certfile']
+            conninfo.transport_options['ssl_trustfile'] = conninfo.ssl[
+                'ca_certs']
+            if conninfo.ssl['cert_reqs'] == ssl.CERT_REQUIRED:
+                conninfo.transport_options['ssl_skip_hostname_check'] = False
+            else:
+                conninfo.transport_options['ssl_skip_hostname_check'] = True
+        else:
+            conninfo.qpid_transport = 'tcp'
+        opts = dict({'host': conninfo.hostname, 'port': conninfo.port,
+                     'username': conninfo.userid,
+                     'password': conninfo.password,
+                     'transport': conninfo.qpid_transport,
+                     'timeout': conninfo.connect_timeout,
+                     'sasl_mechanisms': conninfo.sasl_mechanisms},
+                    **conninfo.transport_options or {})
+        conn = self.Connection(**opts)
+        conn.client = self.client
+        self.session = conn.get_qpid_connection().session()
+        self.transport_receiver = TransportReceiver(self.session,
+                                                    self.delivery_queue,
+                                                    self.w_fd)
+        self.transport_receiver.daemon = True
+        self.transport_receiver.start()
+        return conn
+
+    def close_connection(self, connection):
+        """Close the :class:`Connection` object, and all associated
+        :class:`Channel` objects.
+
+        Iterates through all :class:`Channel` objects associated with the
+        :class:`Connection`, pops them from the list of channels, and calls
+        :meth:Channel.close` on each.
+
+        :param connection: The Connection that should be closed
+        :type connection: Connection
+        """
+        for channel in connection.channels:
+                channel.close()
+
+    def drain_events(self, connection, timeout=0, **kwargs):
+        """Handle and call callbacks for all ready Transport messages.
+
+        Drains all events that are ready for consuming from :class:`FDShim`.
+        Messages must pass through :class:`FDShim` so that an external read
+        file descriptor can be marked as readable, to allow asynchronous I/O
+        to properly occur.
+
+        For each drained event, the message is called to the appropriate
+        callback.  Callbacks are organized by queue name.  The object that
+        is returned from queue_from_fdshim is a tuple containing the queue
+        name, and the message, in that order.
+
+        :param connection: The :class:`Connection` that contains the
+            callbacks, indexed by queue name, which will be called by this
+            method.
+        :type connection: Connection
+        :keyword timeout: The timeout that limits how long this method will
+            run for.  The timeout could interrupt a blocking read that is
+            waiting for a new message, or cause this method to return before
+            all messages are drained.  Defaults to 0.
+        :type timeout: int
+        """
+        start_time = time.time()
+        elapsed_time = -1
+        while elapsed_time < timeout:
+            try:
+                queue, message = self.delivery_queue.get(block=True,
+                                                         timeout=timeout)
+            except Queue.Empty:
+                raise socket.timeout()
+            else:
+                connection._callbacks[queue](message)
+            elapsed_time = time.time() - start_time
+        raise socket.timeout()
+
+    def create_channel(self, connection):
+        """Create and return a :class:`Channel`.
+
+        Creates a new :class:`Channel`, and append the :class:`Channel` to the
+        list of channels known by the :class:`Connection`.  Once the new
+        :class:`Channel` is created, it is returned.
+
+        :param connection: The connection that should support the new
+            :class:`Channel`.
+        :type connection: Connection
+
+        :return: The new Channel that is made.
+        :rtype: :class:`Channel`.
+        """
+        channel = connection.Channel(connection, self)
+        connection.channels.append(channel)
+        return channel
+
+    def on_readable(self, connection, loop):
+        """Handle any read events associated with this Transport.
+
+        This method clears a single message from the externally monitored
+        file descriptor by issuing a read call to the self.fd_shim pipe,
+        which removes a single '0' character that was placed into the pipe
+        by :class:`FDShim`. Once a '0' is read, all available events are
+        drained through a call to :meth:`drain_events`.
+
+        Nothing is expected to be returned from :meth:`drain_events` because
+        :meth:`drain_events` handles messages by calling callbacks that are
+        maintained on the :class:`Connection` object.  When
+        :meth:`drain_events` returns, all associated messages have been
+        handled.
+
+        This method reads as many messages that are available for this
+        Transport, and then returns.  It blocks in the sense that reading
+        and handling a large number of messages may take time, but it does
+        not block waiting for a new message to arrive.  When
+        :meth:`drain_events` is called a timeout is not specified, which
+        causes this behavior.
+
+        One interesting behavior of note is where multiple messages are
+        ready, and this method removes a single '0' character from
+        fd_shim.r, but :meth:`drain_events` may handle an arbitrary amount of
+        messages.  In that case, extra '0' characters may be left on fd_shim
+        to be read, where messages corresponding with those '0' characters
+        have already been handled.  The external epoll loop will incorrectly
+        think additional data is ready for reading, and will call
+        on_readable unnecessarily, once for each '0' to be read. Additional
+        calls to :meth:`on_readable` produce no negative side effects,
+        and will eventually clear out the fd_shim pipe of all symbols
+        correctly.  If new messages show up during this draining period,
+        they will also be properly handled.
+
+        :param connection: The connection associated with the readable
+            events, which contains the callbacks that need to be called for
+            the readables.
+        :type connection: Connection
+        :param loop: The asynchronous loop object that contains epoll like
+            functionality.
+        :type loop: kombu.async.Hub
+        """
+        result = os.read(self.r_fd, 1)
+        if result == '0':
+            try:
+                self.drain_events(connection)
+            except socket.timeout:
+                pass
+
+    @property
+    def default_connection_params(self):
+        """Return a dict with default connection parameters.
+
+        These connection parameters will be used whenever the creator of
+        Transport does not specify a required parameter.
+
+        :return: A dict containing the default parameters.
+        :rtype: dict
+        """
+        return {'userid': 'guest', 'password': 'guest',
+                'port': self.default_port, 'virtual_host': '',
+                'hostname': 'localhost', 'sasl_mechanisms': 'PLAIN'}
diff --git a/requirements/extras/qpid.txt b/requirements/extras/qpid.txt
new file mode 100644
index 0000000..61b8c8c
--- /dev/null
+++ b/requirements/extras/qpid.txt
@@ -0,0 +1,2 @@
+qpid-python>=0.26
+qpid-tools>=0.26
diff --git a/requirements/funtest.txt b/requirements/funtest.txt
index 6ac859b..06cf309 100644
--- a/requirements/funtest.txt
+++ b/requirements/funtest.txt
@@ -22,3 +22,7 @@ django-kombu
 
 # SQS transport
 boto
+
+# Qpid transport
+qpid-python>=0.26
+qpid-tools>=0.26
diff --git a/setup.py b/setup.py
index e0cbe40..3998e3a 100644
--- a/setup.py
+++ b/setup.py
@@ -135,6 +135,7 @@ extras_require = extra['extras_require'] = {
     'librabbitmq': extras('librabbitmq.txt'),
     'pyro': extras('pyro.txt'),
     'slmq': extras('slmq.txt'),
+    'qpid': extras('qpid.txt'),
 }
 
 setup(
